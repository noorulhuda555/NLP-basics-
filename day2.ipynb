{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8cd2bba5-178d-4cdb-8b31-cff3beb51023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c79de-9f0e-4896-a9f3-39a326dddd4c",
   "metadata": {},
   "source": [
    "## USING NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69670f5a-d3b3-4fef-97a2-b5f0a7db485c",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a68695f2-850c-4a25-82a6-5fc37ae813d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMS_DATA.csv', encoding='Windows-1252', index_col='S. No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c89b1873-5ab1-4ed4-93b4-73d529e2f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message_body     Label\n",
       "S. No.                                                             \n",
       "1                              Rofl. Its true to its name  Non-Spam\n",
       "2       The guy did some bitching but I acted like i'd...  Non-Spam\n",
       "3       Pity, * was in mood for that. So...any other s...  Non-Spam\n",
       "4                    Will ü b going to esplanade fr home?  Non-Spam\n",
       "5       This is the 2nd time we have tried 2 contact u...      Spam"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d285b5-1a9c-46f9-aab1-8a5636a0b111",
   "metadata": {},
   "source": [
    "### check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "295ccb79-571f-4708-a8c2-12662c4a2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message_body    0\n",
       "Label           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffbea4c-4966-4faa-a03f-7ea907969443",
   "metadata": {},
   "source": [
    "### Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85f43cbf-f9a5-4e2e-94a6-21ed689745e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(input):\n",
    "    return input.lower()\n",
    "\n",
    "data['Message_body']= data['Message_body'].apply(to_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a4160-3d4f-4ec3-a21a-3e172b26a706",
   "metadata": {},
   "source": [
    "as nltk stopwords are in lowercae, i convert my data into lowercase as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b6bdb6b1-74a2-4c65-ba9d-04a95fb40c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message_body     Label\n",
       "S. No.                                                             \n",
       "1                              rofl. its true to its name  Non-Spam\n",
       "2       the guy did some bitching but i acted like i'd...  Non-Spam\n",
       "3       pity, * was in mood for that. so...any other s...  Non-Spam\n",
       "4                    will ü b going to esplanade fr home?  Non-Spam\n",
       "5       this is the 2nd time we have tried 2 contact u...      Spam"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eecfb-9cf9-4821-89c4-9eea47c0d4de",
   "metadata": {},
   "source": [
    "### remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7361ae87-8c5b-4289-ae2e-693a28238dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(input):\n",
    "    return ''.join(word for word in input if word not in string.punctuation) #if it is not a puntuation mark, include in string\n",
    "\n",
    "data['Message_body']= data['Message_body'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15897e40-cf8d-44ce-ac74-cd7444a6b1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the guy did some bitching but i acted like id ...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pity  was in mood for that soany other suggest...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will ü b going to esplanade fr home</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message_body     Label\n",
       "S. No.                                                             \n",
       "1                               rofl its true to its name  Non-Spam\n",
       "2       the guy did some bitching but i acted like id ...  Non-Spam\n",
       "3       pity  was in mood for that soany other suggest...  Non-Spam\n",
       "4                     will ü b going to esplanade fr home  Non-Spam\n",
       "5       this is the 2nd time we have tried 2 contact u...      Spam"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264800c-223b-4ad1-9ab6-e6f4174554de",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b870ab4e-91e8-4e1a-93b8-e0484be8eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input):\n",
    "    return word_tokenize(input) #using nltk builtin word tokenizer \n",
    "\n",
    "data['tokens']= data['Message_body'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1112e912-379c-44ec-a513-17dc254fa997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the guy did some bitching but i acted like id ...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pity  was in mood for that soany other suggest...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[pity, was, in, mood, for, that, soany, other,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will ü b going to esplanade fr home</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message_body     Label  \\\n",
       "S. No.                                                                \n",
       "1                               rofl its true to its name  Non-Spam   \n",
       "2       the guy did some bitching but i acted like id ...  Non-Spam   \n",
       "3       pity  was in mood for that soany other suggest...  Non-Spam   \n",
       "4                     will ü b going to esplanade fr home  Non-Spam   \n",
       "5       this is the 2nd time we have tried 2 contact u...      Spam   \n",
       "\n",
       "                                                   tokens  \n",
       "S. No.                                                     \n",
       "1                        [rofl, its, true, to, its, name]  \n",
       "2       [the, guy, did, some, bitching, but, i, acted,...  \n",
       "3       [pity, was, in, mood, for, that, soany, other,...  \n",
       "4            [will, ü, b, going, to, esplanade, fr, home]  \n",
       "5       [this, is, the, 2nd, time, we, have, tried, 2,...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d6836-1442-4821-a276-cfa0b791c26e",
   "metadata": {},
   "source": [
    "### Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7a5c4b2-b8e1-4220-b04c-7f4ed2baa62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nooru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52c2fac9-8c96-4bb7-a502-e09c4db2008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the guy did some bitching but i acted like id ...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pity  was in mood for that soany other suggest...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[pity, was, in, mood, for, that, soany, other,...</td>\n",
       "      <td>[pity, mood, soany, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will ü b going to esplanade fr home</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, £750, pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message_body     Label  \\\n",
       "S. No.                                                                \n",
       "1                               rofl its true to its name  Non-Spam   \n",
       "2       the guy did some bitching but i acted like id ...  Non-Spam   \n",
       "3       pity  was in mood for that soany other suggest...  Non-Spam   \n",
       "4                     will ü b going to esplanade fr home  Non-Spam   \n",
       "5       this is the 2nd time we have tried 2 contact u...      Spam   \n",
       "\n",
       "                                                   tokens  \\\n",
       "S. No.                                                      \n",
       "1                        [rofl, its, true, to, its, name]   \n",
       "2       [the, guy, did, some, bitching, but, i, acted,...   \n",
       "3       [pity, was, in, mood, for, that, soany, other,...   \n",
       "4            [will, ü, b, going, to, esplanade, fr, home]   \n",
       "5       [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "\n",
       "                                             clean_tokens  \n",
       "S. No.                                                     \n",
       "1                                      [rofl, true, name]  \n",
       "2       [guy, bitching, acted, like, id, interested, b...  \n",
       "3                        [pity, mood, soany, suggestions]  \n",
       "4                      [ü, b, going, esplanade, fr, home]  \n",
       "5       [2nd, time, tried, 2, contact, u, u, £750, pou...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_word_eng = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopword(tokens):\n",
    "    filtered = [] \n",
    "    for word in tokens:\n",
    "        if word not in stop_word_eng:\n",
    "            filtered.append(word) #eppend to list if not part of stop word listc \n",
    "    return filtered\n",
    "\n",
    "data['clean_tokens'] = data['tokens'].apply(remove_stopword)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9574610-ac15-43f1-9213-afb697a92363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nooru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4af6e-5cd0-4011-9523-a57497db83e7",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2553035-212b-4599-b946-6f27a31c79bb",
   "metadata": {},
   "source": [
    "##### stemming\n",
    "\n",
    "- convert a word to its base form\n",
    "- not grammar aware (may reduce to a word that might be wrong/ doesnot exist)\n",
    "\n",
    "##### Lemmatization\n",
    "\n",
    "- reduces word to its base form\n",
    "- considers context and grammar\n",
    "- returns valid words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c04bd64d-6663-4662-966f-8aac29d1d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "data['stemmed'] = data['clean_tokens'].apply(lambda tokens: [stem.stem(w) for w in tokens])\n",
    "\n",
    "data['lemmatized'] = data['clean_tokens'].apply(lambda tokens: [wnl.lemmatize(w) for w in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0db55a83-ec4d-4d42-a609-15f2941c029f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S. No.\n",
       "1                                     [rofl, true, name]\n",
       "2      [guy, bitch, act, like, id, interest, buy, som...\n",
       "3                           [piti, mood, soani, suggest]\n",
       "4                         [ü, b, go, esplanad, fr, home]\n",
       "5      [2nd, time, tri, 2, contact, u, u, £750, pound...\n",
       "                             ...                        \n",
       "953    [how, favourit, person, today, r, u, workin, h...\n",
       "954                                   [much, got, clean]\n",
       "955             [sorri, da, gone, mad, mani, pend, work]\n",
       "956                               [wat, time, ü, finish]\n",
       "957                                         [glad, talk]\n",
       "Name: stemmed, Length: 957, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stemmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2522cdb-142d-4955-aa77-7d4d8706be27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S. No.\n",
       "1                                     [rofl, true, name]\n",
       "2      [guy, bitching, acted, like, id, interested, b...\n",
       "3                        [pity, mood, soany, suggestion]\n",
       "4                     [ü, b, going, esplanade, fr, home]\n",
       "5      [2nd, time, tried, 2, contact, u, u, £750, pou...\n",
       "                             ...                        \n",
       "953    [hows, favourite, person, today, r, u, workin,...\n",
       "954                                [much, got, cleaning]\n",
       "955          [sorry, da, gone, mad, many, pending, work]\n",
       "956                               [wat, time, ü, finish]\n",
       "957                                      [glad, talking]\n",
       "Name: lemmatized, Length: 957, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccab129-4a45-4800-8af5-741cdd6564c5",
   "metadata": {},
   "source": [
    "### Word frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3286b1c9-46e8-4e5d-ad48-5e6d4b3d09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('u', 210), ('call', 115), ('im', 95), ('2', 83), ('get', 69), ('ur', 66), ('4', 61), ('go', 56), ('free', 47), ('time', 42)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_words = [word for tokens in data['lemmatized'] for word in tokens]\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "print(word_freq.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b5387ef-12f9-4eb1-a942-8c2fbceed734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('u', 193), ('call', 111), ('im', 95), ('2', 83), ('get', 67), ('ur', 66), ('4', 61), ('go', 54), ('free', 47), ('ok', 41)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_words = [word for tokens in data['clean_tokens'] for word in tokens]\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "print(word_freq.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c9e2247-4f57-46f6-9676-a62be73f82d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'u': 193,\n",
       "         'call': 111,\n",
       "         'im': 95,\n",
       "         '2': 83,\n",
       "         'get': 67,\n",
       "         'ur': 66,\n",
       "         '4': 61,\n",
       "         'go': 54,\n",
       "         'free': 47,\n",
       "         'ok': 41,\n",
       "         'dont': 39,\n",
       "         'ltgt': 39,\n",
       "         'like': 38,\n",
       "         'got': 38,\n",
       "         'know': 38,\n",
       "         'time': 37,\n",
       "         'want': 35,\n",
       "         'day': 35,\n",
       "         'see': 34,\n",
       "         'good': 34,\n",
       "         'oh': 34,\n",
       "         'come': 32,\n",
       "         'stop': 32,\n",
       "         'later': 31,\n",
       "         'ü': 30,\n",
       "         'home': 30,\n",
       "         'one': 30,\n",
       "         'ill': 29,\n",
       "         'back': 29,\n",
       "         'tell': 29,\n",
       "         'mobile': 29,\n",
       "         'need': 28,\n",
       "         'send': 28,\n",
       "         'going': 27,\n",
       "         'pls': 27,\n",
       "         'r': 26,\n",
       "         'week': 25,\n",
       "         'lor': 25,\n",
       "         'love': 25,\n",
       "         'give': 24,\n",
       "         'txt': 24,\n",
       "         'text': 23,\n",
       "         'well': 23,\n",
       "         'still': 23,\n",
       "         'phone': 23,\n",
       "         'today': 23,\n",
       "         'claim': 22,\n",
       "         'great': 22,\n",
       "         'hey': 22,\n",
       "         'new': 22,\n",
       "         'take': 22,\n",
       "         'n': 22,\n",
       "         'reply': 21,\n",
       "         'sorry': 21,\n",
       "         'think': 21,\n",
       "         'hi': 21,\n",
       "         'number': 21,\n",
       "         'cant': 21,\n",
       "         'thats': 20,\n",
       "         'da': 20,\n",
       "         'please': 19,\n",
       "         'make': 19,\n",
       "         'ask': 18,\n",
       "         'anything': 18,\n",
       "         'cash': 18,\n",
       "         'dear': 18,\n",
       "         'work': 18,\n",
       "         'night': 18,\n",
       "         'didnt': 18,\n",
       "         'us': 17,\n",
       "         'prize': 17,\n",
       "         'keep': 17,\n",
       "         'yeah': 17,\n",
       "         'wat': 17,\n",
       "         'face': 17,\n",
       "         'hope': 17,\n",
       "         'k': 17,\n",
       "         'already': 16,\n",
       "         'way': 16,\n",
       "         'tonight': 16,\n",
       "         'last': 16,\n",
       "         'wan': 16,\n",
       "         '1': 16,\n",
       "         'really': 15,\n",
       "         'much': 15,\n",
       "         'amp': 15,\n",
       "         '3': 15,\n",
       "         'life': 15,\n",
       "         'na': 15,\n",
       "         'many': 15,\n",
       "         'next': 14,\n",
       "         'contact': 14,\n",
       "         'yes': 14,\n",
       "         'leave': 14,\n",
       "         'tomorrow': 14,\n",
       "         'happy': 14,\n",
       "         'cos': 14,\n",
       "         'soon': 13,\n",
       "         'cool': 13,\n",
       "         'gud': 13,\n",
       "         'also': 13,\n",
       "         'yup': 13,\n",
       "         'thought': 13,\n",
       "         'pick': 13,\n",
       "         'e': 13,\n",
       "         'coming': 13,\n",
       "         'b': 12,\n",
       "         'nice': 12,\n",
       "         'right': 12,\n",
       "         'lol': 12,\n",
       "         'stuff': 12,\n",
       "         'thing': 12,\n",
       "         'meeting': 12,\n",
       "         'hows': 12,\n",
       "         'problem': 12,\n",
       "         'care': 12,\n",
       "         'say': 11,\n",
       "         'havent': 11,\n",
       "         'babe': 11,\n",
       "         'would': 11,\n",
       "         'dinner': 11,\n",
       "         'urgent': 11,\n",
       "         'message': 11,\n",
       "         'place': 11,\n",
       "         'fine': 11,\n",
       "         'customer': 11,\n",
       "         'something': 10,\n",
       "         'house': 10,\n",
       "         'ive': 10,\n",
       "         'people': 10,\n",
       "         'trying': 10,\n",
       "         'mins': 10,\n",
       "         'shows': 10,\n",
       "         'smile': 10,\n",
       "         'even': 10,\n",
       "         'dun': 10,\n",
       "         'first': 10,\n",
       "         'told': 10,\n",
       "         'never': 10,\n",
       "         'help': 10,\n",
       "         'sleep': 10,\n",
       "         'anyway': 10,\n",
       "         'sent': 10,\n",
       "         'guaranteed': 10,\n",
       "         'win': 10,\n",
       "         'boy': 10,\n",
       "         'c': 10,\n",
       "         'latest': 10,\n",
       "         'find': 10,\n",
       "         'let': 10,\n",
       "         'gon': 10,\n",
       "         'g': 10,\n",
       "         'service': 10,\n",
       "         'name': 9,\n",
       "         'wait': 9,\n",
       "         'dat': 9,\n",
       "         'school': 9,\n",
       "         'x': 9,\n",
       "         'wish': 9,\n",
       "         'youre': 9,\n",
       "         'ready': 9,\n",
       "         'every': 9,\n",
       "         'long': 9,\n",
       "         'account': 9,\n",
       "         'statement': 9,\n",
       "         'code': 9,\n",
       "         '‘': 9,\n",
       "         'friend': 9,\n",
       "         'sms': 9,\n",
       "         'buy': 9,\n",
       "         'thanks': 9,\n",
       "         'holiday': 9,\n",
       "         'things': 9,\n",
       "         'nite': 9,\n",
       "         'nokia': 9,\n",
       "         'receive': 9,\n",
       "         'finish': 9,\n",
       "         'birthday': 9,\n",
       "         'heart': 9,\n",
       "         'id': 8,\n",
       "         'another': 8,\n",
       "         'talk': 8,\n",
       "         'away': 8,\n",
       "         'private': 8,\n",
       "         'points': 8,\n",
       "         'expires': 8,\n",
       "         'bad': 8,\n",
       "         'camera': 8,\n",
       "         '16': 8,\n",
       "         'den': 8,\n",
       "         'msg': 8,\n",
       "         'line': 8,\n",
       "         '£1000': 8,\n",
       "         'tc': 8,\n",
       "         'bring': 8,\n",
       "         'hello': 8,\n",
       "         'plan': 8,\n",
       "         'morning': 8,\n",
       "         'award': 8,\n",
       "         'sure': 8,\n",
       "         'better': 8,\n",
       "         'friends': 8,\n",
       "         'waiting': 8,\n",
       "         'said': 8,\n",
       "         'years': 8,\n",
       "         'tone': 8,\n",
       "         'lunch': 8,\n",
       "         'guy': 7,\n",
       "         'else': 7,\n",
       "         'easy': 7,\n",
       "         'per': 7,\n",
       "         'details': 7,\n",
       "         'started': 7,\n",
       "         'important': 7,\n",
       "         'enough': 7,\n",
       "         'ah': 7,\n",
       "         'days': 7,\n",
       "         'best': 7,\n",
       "         '1st': 7,\n",
       "         '2003': 7,\n",
       "         'unredeemed': 7,\n",
       "         'identifier': 7,\n",
       "         'feel': 7,\n",
       "         'awarded': 7,\n",
       "         'ya': 7,\n",
       "         'wont': 7,\n",
       "         'dad': 7,\n",
       "         'called': 7,\n",
       "         'min': 7,\n",
       "         'person': 7,\n",
       "         'maybe': 7,\n",
       "         'play': 7,\n",
       "         'game': 7,\n",
       "         'bt': 7,\n",
       "         'update': 7,\n",
       "         'money': 7,\n",
       "         'fun': 7,\n",
       "         'liao': 7,\n",
       "         'around': 7,\n",
       "         'car': 7,\n",
       "         'show': 7,\n",
       "         'haf': 7,\n",
       "         'baby': 7,\n",
       "         '9': 7,\n",
       "         'bus': 7,\n",
       "         'guys': 7,\n",
       "         'collection': 7,\n",
       "         'smth': 7,\n",
       "         'leh': 7,\n",
       "         'half': 7,\n",
       "         'meet': 7,\n",
       "         'true': 6,\n",
       "         '2nd': 6,\n",
       "         '6': 6,\n",
       "         'quite': 6,\n",
       "         'use': 6,\n",
       "         'shit': 6,\n",
       "         'bit': 6,\n",
       "         'trip': 6,\n",
       "         'weekend': 6,\n",
       "         'says': 6,\n",
       "         'jus': 6,\n",
       "         'rite': 6,\n",
       "         'malaria': 6,\n",
       "         '800': 6,\n",
       "         'landline': 6,\n",
       "         '150ppm': 6,\n",
       "         'big': 6,\n",
       "         'hear': 6,\n",
       "         'everything': 6,\n",
       "         'may': 6,\n",
       "         'always': 6,\n",
       "         'brother': 6,\n",
       "         'try': 6,\n",
       "         'shall': 6,\n",
       "         'sch': 6,\n",
       "         'check': 6,\n",
       "         'fuck': 6,\n",
       "         'draw': 6,\n",
       "         'probably': 6,\n",
       "         'reward': 6,\n",
       "         'enjoy': 6,\n",
       "         '18': 6,\n",
       "         'left': 6,\n",
       "         'little': 6,\n",
       "         'eve': 6,\n",
       "         'job': 6,\n",
       "         'knw': 6,\n",
       "         'todays': 6,\n",
       "         'forgot': 6,\n",
       "         'tot': 6,\n",
       "         'mayb': 6,\n",
       "         'could': 6,\n",
       "         'watching': 6,\n",
       "         'auction': 6,\n",
       "         'might': 6,\n",
       "         'attempt': 6,\n",
       "         'simple': 6,\n",
       "         'course': 6,\n",
       "         'frnd': 6,\n",
       "         '£2000': 6,\n",
       "         'shes': 6,\n",
       "         '£350': 6,\n",
       "         'selected': 6,\n",
       "         'getting': 6,\n",
       "         'support': 6,\n",
       "         'missing': 6,\n",
       "         'haha': 6,\n",
       "         'tried': 5,\n",
       "         'valid': 5,\n",
       "         'huh': 5,\n",
       "         'til': 5,\n",
       "         'decided': 5,\n",
       "         'drink': 5,\n",
       "         'works': 5,\n",
       "         'gas': 5,\n",
       "         'taking': 5,\n",
       "         'believe': 5,\n",
       "         'means': 5,\n",
       "         'visit': 5,\n",
       "         'happened': 5,\n",
       "         'times': 5,\n",
       "         'made': 5,\n",
       "         'though': 5,\n",
       "         'god': 5,\n",
       "         'knew': 5,\n",
       "         'since': 5,\n",
       "         'sat': 5,\n",
       "         'went': 5,\n",
       "         'gods': 5,\n",
       "         'friendship': 5,\n",
       "         'family': 5,\n",
       "         'princess': 5,\n",
       "         'saturday': 5,\n",
       "         'thk': 5,\n",
       "         'colour': 5,\n",
       "         'theres': 5,\n",
       "         'open': 5,\n",
       "         'wif': 5,\n",
       "         'lar': 5,\n",
       "         'lot': 5,\n",
       "         'wasnt': 5,\n",
       "         'xmas': 5,\n",
       "         'part': 5,\n",
       "         'gal': 5,\n",
       "         'plus': 5,\n",
       "         'evening': 5,\n",
       "         'hes': 5,\n",
       "         'dunno': 5,\n",
       "         'driving': 5,\n",
       "         'em': 5,\n",
       "         'two': 5,\n",
       "         'box': 5,\n",
       "         'sir': 5,\n",
       "         'sweet': 5,\n",
       "         'kiss': 5,\n",
       "         'thinking': 5,\n",
       "         'chat': 5,\n",
       "         '£5000': 5,\n",
       "         'await': 5,\n",
       "         'sae': 5,\n",
       "         'eat': 5,\n",
       "         'kate': 5,\n",
       "         'girl': 5,\n",
       "         'aha': 5,\n",
       "         'year': 5,\n",
       "         'apply': 5,\n",
       "         'hair': 5,\n",
       "         'dis': 5,\n",
       "         'price': 5,\n",
       "         'ever': 5,\n",
       "         'buying': 4,\n",
       "         'gave': 4,\n",
       "         'pounds': 4,\n",
       "         'lei': 4,\n",
       "         'least': 4,\n",
       "         'gd': 4,\n",
       "         'tho': 4,\n",
       "         'pete': 4,\n",
       "         'mind': 4,\n",
       "         'company': 4,\n",
       "         'wen': 4,\n",
       "         '£250': 4,\n",
       "         'worse': 4,\n",
       "         'takes': 4,\n",
       "         'meds': 4,\n",
       "         'self': 4,\n",
       "         'delivery': 4,\n",
       "         'join': 4,\n",
       "         'put': 4,\n",
       "         'smiling': 4,\n",
       "         'tmr': 4,\n",
       "         'must': 4,\n",
       "         'okie': 4,\n",
       "         'crazy': 4,\n",
       "         'world': 4,\n",
       "         'wil': 4,\n",
       "         'late': 4,\n",
       "         'ni8': 4,\n",
       "         'alone': 4,\n",
       "         'step': 4,\n",
       "         'lets': 4,\n",
       "         'town': 4,\n",
       "         'leaving': 4,\n",
       "         'bored': 4,\n",
       "         '12hrs': 4,\n",
       "         'seen': 4,\n",
       "         'summer': 4,\n",
       "         'wine': 4,\n",
       "         'together': 4,\n",
       "         'minutes': 4,\n",
       "         'email': 4,\n",
       "         'someone': 4,\n",
       "         'news': 4,\n",
       "         'nothing': 4,\n",
       "         'hour': 4,\n",
       "         'watch': 4,\n",
       "         'thank': 4,\n",
       "         'date': 4,\n",
       "         'xxx': 4,\n",
       "         'thanx': 4,\n",
       "         'whenever': 4,\n",
       "         'complete': 4,\n",
       "         'santa': 4,\n",
       "         'month': 4,\n",
       "         'nope': 4,\n",
       "         'pub': 4,\n",
       "         'busy': 4,\n",
       "         'bed': 4,\n",
       "         'film': 4,\n",
       "         '’': 4,\n",
       "         'online': 4,\n",
       "         'entry': 4,\n",
       "         'chance': 4,\n",
       "         'dreams': 4,\n",
       "         'dog': 4,\n",
       "         'messages': 4,\n",
       "         '£400': 4,\n",
       "         'computer': 4,\n",
       "         'texts': 4,\n",
       "         'rate': 4,\n",
       "         '5': 4,\n",
       "         'okay': 4,\n",
       "         'loving': 4,\n",
       "         'yet': 4,\n",
       "         'drive': 4,\n",
       "         'room': 4,\n",
       "         'old': 4,\n",
       "         'supposed': 4,\n",
       "         'wonderful': 4,\n",
       "         'makes': 4,\n",
       "         'run': 4,\n",
       "         'feeling': 4,\n",
       "         'south': 4,\n",
       "         'poly': 4,\n",
       "         'uncle': 4,\n",
       "         'speak': 4,\n",
       "         'saw': 4,\n",
       "         'either': 4,\n",
       "         'gift': 4,\n",
       "         'music': 4,\n",
       "         'po': 4,\n",
       "         'mine': 4,\n",
       "         'office': 4,\n",
       "         'calls': 4,\n",
       "         'working': 4,\n",
       "         'collect': 4,\n",
       "         'slowly': 4,\n",
       "         'inviting': 4,\n",
       "         '62468': 4,\n",
       "         'yesterday': 4,\n",
       "         'match': 4,\n",
       "         'guess': 4,\n",
       "         'miss': 4,\n",
       "         'games': 4,\n",
       "         'happen': 4,\n",
       "         'poor': 4,\n",
       "         'link': 4,\n",
       "         'oops': 4,\n",
       "         'network': 4,\n",
       "         'actually': 4,\n",
       "         'hw': 4,\n",
       "         'numbers': 4,\n",
       "         'ending': 4,\n",
       "         'added': 4,\n",
       "         'special': 4,\n",
       "         'second': 4,\n",
       "         'arcade': 4,\n",
       "         'interested': 3,\n",
       "         '10p': 3,\n",
       "         'minute': 3,\n",
       "         'o2': 3,\n",
       "         'offers': 3,\n",
       "         'wednesday': 3,\n",
       "         'ard': 3,\n",
       "         'sony': 3,\n",
       "         'mom': 3,\n",
       "         'hours': 3,\n",
       "         'youll': 3,\n",
       "         'texted': 3,\n",
       "         'laugh': 3,\n",
       "         'deep': 3,\n",
       "         'wot': 3,\n",
       "         'v': 3,\n",
       "         'done': 3,\n",
       "         'due': 3,\n",
       "         'ring': 3,\n",
       "         'pobox': 3,\n",
       "         'thinkin': 3,\n",
       "         'relax': 3,\n",
       "         'children': 3,\n",
       "         'handle': 3,\n",
       "         'vomit': 3,\n",
       "         'completely': 3,\n",
       "         'side': 3,\n",
       "         'cs': 3,\n",
       "         'common': 3,\n",
       "         'frm': 3,\n",
       "         'ex': 3,\n",
       "         'project': 3,\n",
       "         'goodnight': 3,\n",
       "         'inside': 3,\n",
       "         'congrats': 3,\n",
       "         'unsubscribe': 3,\n",
       "         'charge': 3,\n",
       "         'afternoon': 3,\n",
       "         'boytoy': 3,\n",
       "         'drop': 3,\n",
       "         'studying': 3,\n",
       "         'info': 3,\n",
       "         'wherever': 3,\n",
       "         '12': 3,\n",
       "         'weeks': 3,\n",
       "         'pm': 3,\n",
       "         'food': 3,\n",
       "         'doesnt': 3,\n",
       "         'gr8': 3,\n",
       "         'reaching': 3,\n",
       "         'bottle': 3,\n",
       "         'joking': 3,\n",
       "         'goin': 3,\n",
       "         '11mths': 3,\n",
       "         'entitled': 3,\n",
       "         'shopping': 3,\n",
       "         'wats': 3,\n",
       "         'especially': 3,\n",
       "         'girls': 3,\n",
       "         'aight': 3,\n",
       "         'sun': 3,\n",
       "         'using': 3,\n",
       "         'er': 3,\n",
       "         'book': 3,\n",
       "         'park': 3,\n",
       "         'story': 3,\n",
       "         'masters': 3,\n",
       "         'cell': 3,\n",
       "         'luv': 3,\n",
       "         'whens': 3,\n",
       "         'ge': 3,\n",
       "         'walk': 3,\n",
       "         'babes': 3,\n",
       "         'hard': 3,\n",
       "         'hurt': 3,\n",
       "         'shop': 3,\n",
       "         'nt': 3,\n",
       "         'pussy': 3,\n",
       "         'problems': 3,\n",
       "         'set': 3,\n",
       "         'hold': 3,\n",
       "         'wkly': 3,\n",
       "         'comp': 3,\n",
       "         'head': 3,\n",
       "         'different': 3,\n",
       "         'picked': 3,\n",
       "         '100': 3,\n",
       "         'test': 3,\n",
       "         '7': 3,\n",
       "         'hmm': 3,\n",
       "         'aiyo': 3,\n",
       "         'parents': 3,\n",
       "         'question': 3,\n",
       "         'youd': 3,\n",
       "         'sounds': 3,\n",
       "         'regards': 3,\n",
       "         'full': 3,\n",
       "         'england': 3,\n",
       "         'start': 3,\n",
       "         'alright': 3,\n",
       "         'look': 3,\n",
       "         'missed': 3,\n",
       "         'mr': 3,\n",
       "         'wit': 3,\n",
       "         '£500': 3,\n",
       "         '£100': 3,\n",
       "         'weekly': 3,\n",
       "         'tcs': 3,\n",
       "         'pretty': 3,\n",
       "         'word': 3,\n",
       "         'gone': 3,\n",
       "         'land': 3,\n",
       "         '3030': 3,\n",
       "         'remember': 3,\n",
       "         'xx': 3,\n",
       "         'darlin': 3,\n",
       "         'real': 3,\n",
       "         'sitting': 3,\n",
       "         'grins': 3,\n",
       "         'checking': 3,\n",
       "         'chikku': 3,\n",
       "         'wants': 3,\n",
       "         'via': 3,\n",
       "         'fone': 3,\n",
       "         'pain': 3,\n",
       "         'hurts': 3,\n",
       "         'staying': 3,\n",
       "         'pa': 3,\n",
       "         'reach': 3,\n",
       "         'mobiles': 3,\n",
       "         'access': 3,\n",
       "         'mob': 3,\n",
       "         'card': 3,\n",
       "         'saying': 3,\n",
       "         'ipod': 3,\n",
       "         'de': 3,\n",
       "         'convey': 3,\n",
       "         'whats': 3,\n",
       "         'mates': 3,\n",
       "         'till': 3,\n",
       "         'doctor': 3,\n",
       "         'nobody': 3,\n",
       "         'omg': 3,\n",
       "         'dream': 3,\n",
       "         'boys': 3,\n",
       "         'mark': 3,\n",
       "         'warner': 3,\n",
       "         'small': 3,\n",
       "         'allah': 3,\n",
       "         'tones': 3,\n",
       "         'operator': 3,\n",
       "         'rates': 3,\n",
       "         'sign': 3,\n",
       "         'prob': 3,\n",
       "         'energy': 3,\n",
       "         'wrong': 3,\n",
       "         'write': 3,\n",
       "         'talking': 3,\n",
       "         'st': 3,\n",
       "         'amazing': 3,\n",
       "         '08000930705': 3,\n",
       "         'glad': 3,\n",
       "         'charity': 3,\n",
       "         'present': 3,\n",
       "         'video': 3,\n",
       "         'rental': 3,\n",
       "         'mths': 3,\n",
       "         'ho': 3,\n",
       "         'comedy': 3,\n",
       "         'tick': 3,\n",
       "         'lesson': 3,\n",
       "         'others': 3,\n",
       "         'sell': 3,\n",
       "         'semester': 3,\n",
       "         'monday': 3,\n",
       "         'shower': 3,\n",
       "         'hospital': 3,\n",
       "         'mean': 3,\n",
       "         '750': 3,\n",
       "         'anytime': 3,\n",
       "         'none': 3,\n",
       "         'finally': 3,\n",
       "         'used': 3,\n",
       "         'came': 3,\n",
       "         'é': 3,\n",
       "         'acted': 2,\n",
       "         'esplanade': 2,\n",
       "         'pound': 2,\n",
       "         'btnationalrate': 2,\n",
       "         '250': 2,\n",
       "         'credit': 2,\n",
       "         'juz': 2,\n",
       "         'exam': 2,\n",
       "         'indians': 2,\n",
       "         'sometime': 2,\n",
       "         'round': 2,\n",
       "         'hahahause': 2,\n",
       "         'brain': 2,\n",
       "         'nigeria': 2,\n",
       "         'happiness': 2,\n",
       "         'share': 2,\n",
       "         'wear': 2,\n",
       "         'ic': 2,\n",
       "         'cars': 2,\n",
       "         'urself': 2,\n",
       "         'armand': 2,\n",
       "         'asked': 2,\n",
       "         'india': 2,\n",
       "         'mega': 2,\n",
       "         'bill': 2,\n",
       "         'giv': 2,\n",
       "         'seeing': 2,\n",
       "         'gastroenteritis': 2,\n",
       "         'replace': 2,\n",
       "         'loss': 2,\n",
       "         'temp': 2,\n",
       "         'reduce': 2,\n",
       "         'limiting': 2,\n",
       "         'illness': 2,\n",
       "         'total': 2,\n",
       "         'sim': 2,\n",
       "         'basically': 2,\n",
       "         'sipix': 2,\n",
       "         'digital': 2,\n",
       "         'within': 2,\n",
       "         'p': 2,\n",
       "         'skip': 2,\n",
       "         'outside': 2,\n",
       "         'miles': 2,\n",
       "         'letters': 2,\n",
       "         'nyt': 2,\n",
       "         'treat': 2,\n",
       "         'somebody': 2,\n",
       "         'role': 2,\n",
       "         'model': 2,\n",
       "         'giving': 2,\n",
       "         'reason': 2,\n",
       "         'looked': 2,\n",
       "         'mad': 2,\n",
       "         'gym': 2,\n",
       "         'power': 2,\n",
       "         'stupid': 2,\n",
       "         'uni': 2,\n",
       "         'law': 2,\n",
       "         'outta': 2,\n",
       "         'wake': 2,\n",
       "         'gt': 2,\n",
       "         'services': 2,\n",
       "         'goto': 2,\n",
       "         'extra': 2,\n",
       "         'asap': 2,\n",
       "         'goes': 2,\n",
       "         'mum': 2,\n",
       "         'official': 2,\n",
       "         'wallpaper': 2,\n",
       "         'bought': 2,\n",
       "         'eggs': 2,\n",
       "         '2p': 2,\n",
       "         'germany': 2,\n",
       "         'island': 2,\n",
       "         'picking': 2,\n",
       "         'hai': 2,\n",
       "         'waste': 2,\n",
       "         'weekends': 2,\n",
       "         '150p': 2,\n",
       "         'luck': 2,\n",
       "         'wheres': 2,\n",
       "         'garden': 2,\n",
       "         'selection': 2,\n",
       "         'bulbs': 2,\n",
       "         'seeds': 2,\n",
       "         'worth': 2,\n",
       "         '£3350': 2,\n",
       "         'scotsman': 2,\n",
       "         'go2': 2,\n",
       "         'notxtcouk': 2,\n",
       "         'amused': 2,\n",
       "         'moment': 2,\n",
       "         'spend': 2,\n",
       "         '2nite': 2,\n",
       "         'inc': 2,\n",
       "         'december': 2,\n",
       "         '08002986906': 2,\n",
       "         'cause': 2,\n",
       "         'amt': 2,\n",
       "         'wishing': 2,\n",
       "         'beautiful': 2,\n",
       "         'except': 2,\n",
       "         'address': 2,\n",
       "         'sing': 2,\n",
       "         'preferably': 2,\n",
       "         'needs': 2,\n",
       "         'bud': 2,\n",
       "         '0800': 2,\n",
       "         'kind': 2,\n",
       "         'loves': 2,\n",
       "         'train': 2,\n",
       "         'street': 2,\n",
       "         'booked': 2,\n",
       "         'lessons': 2,\n",
       "         'slow': 2,\n",
       "         'everybody': 2,\n",
       "         'sit': 2,\n",
       "         'calling': 2,\n",
       "         'ones': 2,\n",
       "         'bright': 2,\n",
       "         'light': 2,\n",
       "         '4eva': 2,\n",
       "         'shu': 2,\n",
       "         'looking': 2,\n",
       "         'tat': 2,\n",
       "         'yijue': 2,\n",
       "         'mate': 2,\n",
       "         'mah': 2,\n",
       "         'earlier': 2,\n",
       "         'far': 2,\n",
       "         'angry': 2,\n",
       "         'cream': 2,\n",
       "         'oso': 2,\n",
       "         'wanted': 2,\n",
       "         'kisses': 2,\n",
       "         'quick': 2,\n",
       "         'discount': 2,\n",
       "         'shd': 2,\n",
       "         'exactly': 2,\n",
       "         'celebration': 2,\n",
       "         'gentle': 2,\n",
       "         'previous': 2,\n",
       "         'fell': 2,\n",
       "         'toopray': 2,\n",
       "         'bucks': 2,\n",
       "         'california': 2,\n",
       "         '08718726270': 2,\n",
       "         'barely': 2,\n",
       "         'isnt': 2,\n",
       "         'yuo': 2,\n",
       "         'tihs': 2,\n",
       "         'sport': 2,\n",
       "         'radio': 2,\n",
       "         'connection': 2,\n",
       "         'final': 2,\n",
       "         'figure': 2,\n",
       "         'couple': 2,\n",
       "         'wed': 2,\n",
       "         'randomly': 2,\n",
       "         'loyal': 2,\n",
       "         'customers': 2,\n",
       "         '09066380611': 2,\n",
       "         '60pmin': 2,\n",
       "         '08712460324': 2,\n",
       "         'nat': 2,\n",
       "         'iouri': 2,\n",
       "         'wylie': 2,\n",
       "         'select': 2,\n",
       "         'red': 2,\n",
       "         'living': 2,\n",
       "         'winning': 2,\n",
       "         'difficult': 2,\n",
       "         'neva': 2,\n",
       "         'lab': 2,\n",
       "         'cut': 2,\n",
       "         'business': 2,\n",
       "         'surprise': 2,\n",
       "         'sofa': 2,\n",
       "         'planning': 2,\n",
       "         'without': 2,\n",
       "         'wks': 2,\n",
       "         'awake': 2,\n",
       "         'snow': 2,\n",
       "         'wouldnt': 2,\n",
       "         'feb': 2,\n",
       "         'end': 2,\n",
       "         'almost': 2,\n",
       "         'deal': 2,\n",
       "         'voice': 2,\n",
       "         'surely': 2,\n",
       "         'lik': 2,\n",
       "         'sending': 2,\n",
       "         'longer': 2,\n",
       "         'walking': 2,\n",
       "         'hand': 2,\n",
       "         'pleasure': 2,\n",
       "         'save': 2,\n",
       "         'print': 2,\n",
       "         'fyi': 2,\n",
       "         'tampa': 2,\n",
       "         'ringtone': 2,\n",
       "         'flag': 2,\n",
       "         '£150': 2,\n",
       "         'sister': 2,\n",
       "         'favorite': 2,\n",
       "         'amount': 2,\n",
       "         '730': 2,\n",
       "         'thursday': 2,\n",
       "         'yay': 2,\n",
       "         'cheers': 2,\n",
       "         'bb': 2,\n",
       "         'bold': 2,\n",
       "         'fixed': 2,\n",
       "         'bank': 2,\n",
       "         'london': 2,\n",
       "         'alex': 2,\n",
       "         'cd': 2,\n",
       "         'vouchers': 2,\n",
       "         '87066': 2,\n",
       "         '09061213237': 2,\n",
       "         '177': 2,\n",
       "         'm227xy': 2,\n",
       "         'xy': 2,\n",
       "         'excellent': 2,\n",
       "         'hate': 2,\n",
       "         'ull': 2,\n",
       "         'forget': 2,\n",
       "         'possession': 2,\n",
       "         'vikky': 2,\n",
       "         'etc': 2,\n",
       "         'fix': 2,\n",
       "         'suite': 2,\n",
       "         'bout': 2,\n",
       "         'doin': 2,\n",
       "         'somethin': 2,\n",
       "         'ni8swt': 2,\n",
       "         'meaning': 2,\n",
       "         'girlfrnd': 2,\n",
       "         'f': 2,\n",
       "         'recently': 2,\n",
       "         'anyone': 2,\n",
       "         'cbe': 2,\n",
       "         'chennai': 2,\n",
       "         'study': 2,\n",
       "         'dearslp': 2,\n",
       "         'welltake': 2,\n",
       "         'careswt': 2,\n",
       "         'dreamsmuah': 2,\n",
       "         'juicy': 2,\n",
       "         'pizza': 2,\n",
       "         'ride': 2,\n",
       "         'site': 2,\n",
       "         'valued': 2,\n",
       "         'bother': 2,\n",
       "         'exams': 2,\n",
       "         'words': 2,\n",
       "         'sum1': 2,\n",
       "         'slept': 2,\n",
       "         'wid': 2,\n",
       "         'l8r': 2,\n",
       "         'die': 2,\n",
       "         'cover': 2,\n",
       "         'march': 2,\n",
       "         'rs': 2,\n",
       "         'exe': 2,\n",
       "         'freefone': 2,\n",
       "         '08000839402': 2,\n",
       "         'costa': 2,\n",
       "         'del': 2,\n",
       "         'sol': 2,\n",
       "         '09050090044': 2,\n",
       "         'toclaim': 2,\n",
       "         'pobox334': 2,\n",
       "         'stockport': 2,\n",
       "         'sk38xh': 2,\n",
       "         'cost£150pm': 2,\n",
       "         'max10mins': 2,\n",
       "         '85': 2,\n",
       "         'spook': 2,\n",
       "         '8007': 2,\n",
       "         'zed': 2,\n",
       "         'sarasota': 2,\n",
       "         'muz': 2,\n",
       "         'std': 2,\n",
       "         'facebook': 2,\n",
       "         'mrt': 2,\n",
       "         'sleepin': 2,\n",
       "         'fucking': 2,\n",
       "         'crave': 2,\n",
       "         'wishes': 2,\n",
       "         'water': 2,\n",
       "         'tog': 2,\n",
       "         'player': 2,\n",
       "         'birth': 2,\n",
       "         'party': 2,\n",
       "         'parking': 2,\n",
       "         'eyes': 2,\n",
       "         'tel': 2,\n",
       "         'fingers': 2,\n",
       "         'pray': 2,\n",
       "         'shut': 2,\n",
       "         'kids': 2,\n",
       "         'pissed': 2,\n",
       "         'yoga': 2,\n",
       "         'near': 2,\n",
       "         'training': 2,\n",
       "         'sucks': 2,\n",
       "         'relation': 2,\n",
       "         '2u': 2,\n",
       "         'cherish': 2,\n",
       "         'workin': 2,\n",
       "         'orchard': 2,\n",
       "         'argue': 2,\n",
       "         'remind': 2,\n",
       "         'yor': 2,\n",
       "         'cancer': 2,\n",
       "         'izzit': 2,\n",
       "         'reached': 2,\n",
       "         'understanding': 2,\n",
       "         'break': 2,\n",
       "         'vry': 2,\n",
       "         'hv': 2,\n",
       "         'loved': 2,\n",
       "         'frnds': 2,\n",
       "         'hit': 2,\n",
       "         'ran': 2,\n",
       "         ...})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a2b4fe-6892-4fea-9e30-5ba74abc133d",
   "metadata": {},
   "source": [
    "## USING SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0eb8c449-4b86-4885-b64b-882cff57b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912f340-0c60-471c-a5ea-b71ba9d1e603",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ffb6462e-8727-4e0a-a19c-a596e126f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ab265-efc3-4b8a-b38b-b9bd284c4ffa",
   "metadata": {},
   "source": [
    "spacy.load, Loads a Pretrained Language Model which is a small English model provided by spaCy.\n",
    "\n",
    "It includes:\n",
    "- Tokenizer = splits a big sentence into smaller pieces\n",
    "- Part-of-speech tagger = identifies noun, adjective, verb etc\n",
    "- Lemmatizer = reduces words to base form\n",
    "- Named Entity Recognizer = identifies real life nouns\n",
    "- Dependency Parser = identifies word relations and parts of sentences\n",
    "\n",
    "The nlp object becomes your NLP processing pipeline.When you pass text to it it tokenizes, applies POS tagging, lemmatizaton and NER to text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3f4e392-bff3-4583-9be2-1bd05eb12066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SMS_DATA.csv', encoding='Windows-1252', index_col='S. No.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88e97b-dcf5-4255-bc81-8bc06a0af238",
   "metadata": {},
   "source": [
    "### process text using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ea02096-9854-40de-8a61-640aa1316046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text_clean = text.lower().translate(str.maketrans('', '', string.punctuation)) #conevrt to lowercase and remove Punctuations\n",
    "    processed = nlp(text_clean)\n",
    "    lemmas = [token.lemma_ for token in processed if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "    return lemmas\n",
    "\n",
    "df['lemmas'] = df['Message_body'].apply(process_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0647d087-d976-4055-8d76-3b8819ae6c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S. No.\n",
       "1                                           [rofl, true]\n",
       "2      [guy, bitching, act, like, d, interested, buy,...\n",
       "3                        [pity, mood, soany, suggestion]\n",
       "4                        [ü, b, go, esplanade, fr, home]\n",
       "5      [2nd, time, try, 2, contact, u, u, win, £, 750...\n",
       "                             ...                        \n",
       "953    [s, favourite, person, today, r, u, workin, ha...\n",
       "954                                         [get, clean]\n",
       "955                    [sorry, da, go, mad, pende, work]\n",
       "956                               [wat, time, ü, finish]\n",
       "957                                         [glad, talk]\n",
       "Name: lemmas, Length: 957, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4aaae-a4cb-4109-bc81-68aa18a6265d",
   "metadata": {},
   "source": [
    "### Word distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "01965b38-7223-4eda-ad54-aabb28274ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rofl',\n",
       " 'true',\n",
       " 'guy',\n",
       " 'bitching',\n",
       " 'act',\n",
       " 'like',\n",
       " 'd',\n",
       " 'interested',\n",
       " 'buy',\n",
       " 'week',\n",
       " 'give',\n",
       " 'free',\n",
       " 'pity',\n",
       " 'mood',\n",
       " 'soany',\n",
       " 'suggestion',\n",
       " 'ü',\n",
       " 'b',\n",
       " 'go',\n",
       " 'esplanade',\n",
       " 'fr',\n",
       " 'home',\n",
       " '2nd',\n",
       " 'time',\n",
       " 'try',\n",
       " '2',\n",
       " 'contact',\n",
       " 'u',\n",
       " 'u',\n",
       " 'win',\n",
       " '£',\n",
       " '750',\n",
       " 'pound',\n",
       " 'prize',\n",
       " '2',\n",
       " 'claim',\n",
       " 'easy',\n",
       " '087187272008',\n",
       " 'now1',\n",
       " '10p',\n",
       " 'minute',\n",
       " 'btnationalrate',\n",
       " 'reminder',\n",
       " 'o2',\n",
       " '250',\n",
       " 'pound',\n",
       " 'free',\n",
       " 'credit',\n",
       " 'detail',\n",
       " 'great',\n",
       " 'offer',\n",
       " 'pls',\n",
       " 'reply',\n",
       " '2',\n",
       " 'text',\n",
       " 'valid',\n",
       " 'house',\n",
       " 'postcode',\n",
       " 'huh',\n",
       " 'y',\n",
       " 'lei',\n",
       " 'not',\n",
       " 'wait',\n",
       " 'til',\n",
       " 'wednesday',\n",
       " 'ard',\n",
       " '6',\n",
       " 'like',\n",
       " 'dat',\n",
       " 'lor',\n",
       " 'ok',\n",
       " 'lor',\n",
       " 'sony',\n",
       " 'ericsson',\n",
       " 'salesman',\n",
       " 'ask',\n",
       " 'shuhui',\n",
       " 'gd',\n",
       " '2',\n",
       " 'use',\n",
       " 'consider',\n",
       " 'dump',\n",
       " 'heap',\n",
       " 'mom',\n",
       " 'decide',\n",
       " 'come',\n",
       " 'lowes',\n",
       " 'bore',\n",
       " 'lor',\n",
       " 'juz',\n",
       " 'lor',\n",
       " 'not',\n",
       " 'ltgt',\n",
       " 'hour',\n",
       " 'imma',\n",
       " 'flip',\n",
       " 'shit',\n",
       " 'sorry',\n",
       " 'ill',\n",
       " 'later',\n",
       " 'mean',\n",
       " 'calculation',\n",
       " 'ltgt',\n",
       " 'unit',\n",
       " 'ltgt',\n",
       " 'school',\n",
       " 'expensive',\n",
       " 'start',\n",
       " 'practice',\n",
       " 'accent',\n",
       " 'important',\n",
       " 'decide',\n",
       " '4years',\n",
       " 'dental',\n",
       " 'school',\n",
       " 'll',\n",
       " 'nmde',\n",
       " 'exam',\n",
       " 'yes',\n",
       " 's',\n",
       " 'u',\n",
       " 'texte',\n",
       " 'pshewmissing',\n",
       " 'yeh',\n",
       " 'indians',\n",
       " 'nice',\n",
       " 'tho',\n",
       " 'kane',\n",
       " 'bit',\n",
       " 'shud',\n",
       " '4',\n",
       " 'drink',\n",
       " 'soon',\n",
       " 'mite',\n",
       " 'hav',\n",
       " '2',\n",
       " '2',\n",
       " 'da',\n",
       " 'work',\n",
       " '4',\n",
       " 'laugh',\n",
       " 'soon',\n",
       " 'love',\n",
       " 'pete',\n",
       " 'x',\n",
       " 'x',\n",
       " 'mind',\n",
       " 've',\n",
       " 'get',\n",
       " 'gas',\n",
       " 'round',\n",
       " 'trip',\n",
       " 'bar',\n",
       " 'sudden',\n",
       " 'influx',\n",
       " 'cash',\n",
       " 'hahahause',\n",
       " 'brain',\n",
       " 'dear',\n",
       " 'safe',\n",
       " 'trip',\n",
       " 'nigeria',\n",
       " 'wish',\n",
       " 'happiness',\n",
       " 'soon',\n",
       " 'company',\n",
       " 'share',\n",
       " 'moment',\n",
       " 'wen',\n",
       " 'spiritual',\n",
       " 'deep',\n",
       " 's',\n",
       " 'great',\n",
       " 'cool',\n",
       " 'time',\n",
       " 'think',\n",
       " 'know',\n",
       " 'wot',\n",
       " 'people',\n",
       " 'wear',\n",
       " 't',\n",
       " 'shirt',\n",
       " 'jumper',\n",
       " 'hat',\n",
       " 'belt',\n",
       " 'know',\n",
       " 'r',\n",
       " 'cribbs',\n",
       " 'try',\n",
       " 'weekend',\n",
       " 'v',\n",
       " 'ic',\n",
       " 'lotta',\n",
       " 'childporn',\n",
       " 'car',\n",
       " 'hi',\n",
       " 'durban',\n",
       " 'number',\n",
       " 'm',\n",
       " 'take',\n",
       " 'derek',\n",
       " 'amp',\n",
       " 'taylor',\n",
       " 'walmart',\n",
       " 'm',\n",
       " 'time',\n",
       " 'leave',\n",
       " 'mouse',\n",
       " 'desk',\n",
       " 'ill',\n",
       " 'text',\n",
       " 'priscilla',\n",
       " 'ready',\n",
       " 'u',\n",
       " 'not',\n",
       " 'get',\n",
       " 'urself',\n",
       " 'jacket',\n",
       " 'ah',\n",
       " 'armand',\n",
       " 'say',\n",
       " 'ass',\n",
       " 'epsilon',\n",
       " 'yeah',\n",
       " 'jus',\n",
       " 'rite',\n",
       " 'ask',\n",
       " '3mobile',\n",
       " '0870',\n",
       " 'chatline',\n",
       " 'inclu',\n",
       " 'free',\n",
       " 'mins',\n",
       " 'india',\n",
       " 'cust',\n",
       " 'servs',\n",
       " 'se',\n",
       " 'yes',\n",
       " 'l8er',\n",
       " 'get',\n",
       " 'mega',\n",
       " 'bill',\n",
       " '3',\n",
       " 'not',\n",
       " 'giv',\n",
       " 'shit',\n",
       " 'bailiff',\n",
       " 'day',\n",
       " 'o',\n",
       " '£',\n",
       " '250',\n",
       " '3',\n",
       " 'want',\n",
       " '£',\n",
       " '800',\n",
       " 'sleepingand',\n",
       " 'surfing',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'attached',\n",
       " 'see',\n",
       " 'day',\n",
       " 'know',\n",
       " 'good',\n",
       " 'babe',\n",
       " 'teach',\n",
       " 'class',\n",
       " 'midnight',\n",
       " 'want',\n",
       " 'explicit',\n",
       " 'sex',\n",
       " '30',\n",
       " 'sec',\n",
       " 'ring',\n",
       " '02073162414',\n",
       " 'cost',\n",
       " '20pmin',\n",
       " 'gsex',\n",
       " 'pobox',\n",
       " '2667',\n",
       " 'wc1n',\n",
       " '3xx',\n",
       " 'aiyah',\n",
       " 'ok',\n",
       " 'wat',\n",
       " 'long',\n",
       " 'get',\n",
       " 'improve',\n",
       " 'wat',\n",
       " 'know',\n",
       " 'thinkin',\n",
       " 'malaria',\n",
       " 'relax',\n",
       " 'child',\n",
       " 'not',\n",
       " 'handle',\n",
       " 'malaria',\n",
       " 'bad',\n",
       " 'gastroenteritis',\n",
       " 'take',\n",
       " 'replace',\n",
       " 'loss',\n",
       " 'temp',\n",
       " 'reduce',\n",
       " 'malaria',\n",
       " 'med',\n",
       " 'vomit',\n",
       " 'self',\n",
       " 'limit',\n",
       " 'illness',\n",
       " 'mean',\n",
       " 'day',\n",
       " 'completely',\n",
       " 'stop',\n",
       " 'ok',\n",
       " 'number',\n",
       " 'hey',\n",
       " 'chief',\n",
       " 'bell',\n",
       " 'need',\n",
       " 'talk',\n",
       " 'royal',\n",
       " 'visit',\n",
       " '1st',\n",
       " 'june',\n",
       " 'happen',\n",
       " 'adventure',\n",
       " 'compliment',\n",
       " 'away',\n",
       " 'system',\n",
       " 'think',\n",
       " 'tantrum',\n",
       " 'finish',\n",
       " 'yeah',\n",
       " 'ill',\n",
       " 'point',\n",
       " 'effect',\n",
       " 'irritation',\n",
       " 'ignore',\n",
       " 'total',\n",
       " 'disappointment',\n",
       " 'texte',\n",
       " 'crazy',\n",
       " 'shit',\n",
       " 'get',\n",
       " 'private',\n",
       " '2003',\n",
       " 'account',\n",
       " 'statement',\n",
       " 'show',\n",
       " '800',\n",
       " 'unredeemed',\n",
       " 'sim',\n",
       " 'point',\n",
       " '08718738001',\n",
       " 'identifier',\n",
       " 'code',\n",
       " '49557',\n",
       " 'expire',\n",
       " '261104',\n",
       " 'want',\n",
       " 'tell',\n",
       " 'bad',\n",
       " 'feel',\n",
       " 'basically',\n",
       " 'time',\n",
       " 'text',\n",
       " 'lately',\n",
       " 'need',\n",
       " 'drug',\n",
       " 'award',\n",
       " 'sipix',\n",
       " 'digital',\n",
       " 'camera',\n",
       " '09061221061',\n",
       " 'landline',\n",
       " 'delivery',\n",
       " '28days',\n",
       " 't',\n",
       " 'cs',\n",
       " 'box177',\n",
       " 'm221bp',\n",
       " '2yr',\n",
       " 'warranty',\n",
       " '150ppm',\n",
       " '16',\n",
       " 'p',\n",
       " 'p£399',\n",
       " 'go',\n",
       " 'join',\n",
       " 'tomorrow',\n",
       " 's',\n",
       " 'cool',\n",
       " 'want',\n",
       " 'big',\n",
       " 'chic',\n",
       " 'common',\n",
       " 'declare',\n",
       " 'not',\n",
       " 'want',\n",
       " 'hear',\n",
       " 'pls',\n",
       " 'send',\n",
       " 'company',\n",
       " 'saibaba',\n",
       " 'colany',\n",
       " 'way',\n",
       " 've',\n",
       " 'skip',\n",
       " 'right',\n",
       " 'outside',\n",
       " 'house',\n",
       " 'house',\n",
       " 'pull',\n",
       " 'mile',\n",
       " 'smile',\n",
       " 'r',\n",
       " 'frm',\n",
       " 'letter',\n",
       " 'u',\n",
       " 'know',\n",
       " 'd',\n",
       " 'difference',\n",
       " 'smile',\n",
       " 'ur',\n",
       " 'face',\n",
       " 'keep',\n",
       " 'happy',\n",
       " 'mile',\n",
       " 'away',\n",
       " 'u',\n",
       " 'smile',\n",
       " 'good',\n",
       " 'nyt',\n",
       " 'ya',\n",
       " 'm',\n",
       " 'referin',\n",
       " 'meis',\n",
       " 'ex',\n",
       " 'wat',\n",
       " 'ah',\n",
       " 'waitin',\n",
       " '4',\n",
       " 'u',\n",
       " 'treat',\n",
       " 'somebody',\n",
       " 'shld',\n",
       " 'b',\n",
       " 'rich',\n",
       " 'liaoso',\n",
       " 'gd',\n",
       " 'den',\n",
       " 'u',\n",
       " 'dun',\n",
       " 'work',\n",
       " 'frm',\n",
       " 'tmr',\n",
       " 'onwards',\n",
       " 'great',\n",
       " 'role',\n",
       " 'model',\n",
       " 'give',\n",
       " 'wish',\n",
       " 'day',\n",
       " 'miracle',\n",
       " 'god',\n",
       " 'reason',\n",
       " 'wish',\n",
       " 'know',\n",
       " 'not',\n",
       " 've',\n",
       " 'look',\n",
       " 'young',\n",
       " 'great',\n",
       " 'day',\n",
       " 'oh',\n",
       " 'okie',\n",
       " 'lorwe',\n",
       " 'sit',\n",
       " 'yes',\n",
       " 'leave',\n",
       " 'ltgt',\n",
       " 'ltgt',\n",
       " 'leave',\n",
       " 'make',\n",
       " 'dinner',\n",
       " 'it‘s',\n",
       " 'reassure',\n",
       " 'crazy',\n",
       " 'world',\n",
       " 'go',\n",
       " 'project',\n",
       " 'centre',\n",
       " 'lol',\n",
       " 'mad',\n",
       " 'wake',\n",
       " 'give',\n",
       " 'machan',\n",
       " 'gym',\n",
       " 'tomorrow',\n",
       " 'wil',\n",
       " 'come',\n",
       " 'late',\n",
       " 'goodnight',\n",
       " 'want',\n",
       " 'inside',\n",
       " 'night',\n",
       " 'god',\n",
       " 'love',\n",
       " 'limit',\n",
       " 'god',\n",
       " 'grace',\n",
       " 'measure',\n",
       " 'god',\n",
       " 'power',\n",
       " 'boundary',\n",
       " 'u',\n",
       " 'god',\n",
       " 'endless',\n",
       " 'blessing',\n",
       " 'ur',\n",
       " 'life',\n",
       " 'gud',\n",
       " 'ni8',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'stupid',\n",
       " 'hear',\n",
       " 'will',\n",
       " 'not',\n",
       " 'tell',\n",
       " 'dad',\n",
       " 'call',\n",
       " 'brother',\n",
       " 'speak',\n",
       " 'wait',\n",
       " 'msg',\n",
       " 'ltgt',\n",
       " 'min',\n",
       " 'easy',\n",
       " 'account',\n",
       " 'identification',\n",
       " 'tomorrow',\n",
       " 'uni',\n",
       " 'apo',\n",
       " 'mokka',\n",
       " 'player',\n",
       " 'private',\n",
       " '2003',\n",
       " 'account',\n",
       " 'statement',\n",
       " '07808247860',\n",
       " 'show',\n",
       " '800',\n",
       " 'unredeemed',\n",
       " 's',\n",
       " 'm',\n",
       " 'point',\n",
       " '08719899229',\n",
       " 'identifier',\n",
       " 'code',\n",
       " '40411',\n",
       " 'expire',\n",
       " '061104',\n",
       " 'love',\n",
       " 'law',\n",
       " 'happy',\n",
       " 'person',\n",
       " 'love',\n",
       " 'way',\n",
       " 'friendship',\n",
       " 'law',\n",
       " 'ur',\n",
       " 'friend',\n",
       " 'feel',\n",
       " 'alive',\n",
       " 'gud',\n",
       " 'night',\n",
       " 'step',\n",
       " '2',\n",
       " 'outta',\n",
       " 'way',\n",
       " 'congrat',\n",
       " 'wake',\n",
       " 'gt',\n",
       " 'sm',\n",
       " 'service',\n",
       " 'inclusive',\n",
       " 'text',\n",
       " 'credit',\n",
       " 'pls',\n",
       " 'goto',\n",
       " 'wwwcomuknet',\n",
       " 'login',\n",
       " '3qxj9',\n",
       " 'unsubscribe',\n",
       " 'stop',\n",
       " 'extra',\n",
       " 'charge',\n",
       " 'help',\n",
       " '08702840625comuk',\n",
       " '220cm2',\n",
       " '9ae',\n",
       " 'yes',\n",
       " 'trust',\n",
       " 'u',\n",
       " 'buy',\n",
       " 'new',\n",
       " 'stuff',\n",
       " 'asap',\n",
       " 'try',\n",
       " 'good',\n",
       " 'afternoon',\n",
       " 'love',\n",
       " 'go',\n",
       " 'day',\n",
       " 'sleep',\n",
       " 'hope',\n",
       " 'boytoy',\n",
       " 'think',\n",
       " 'cool',\n",
       " 'shall',\n",
       " 'tip',\n",
       " 'home',\n",
       " 'get',\n",
       " 'drop',\n",
       " 'later',\n",
       " 'let',\n",
       " 'town',\n",
       " 'tonight',\n",
       " 'maybe',\n",
       " 'mum',\n",
       " 'think',\n",
       " 'rule',\n",
       " 'tamilnaduthen',\n",
       " 'tough',\n",
       " 'people',\n",
       " 'marvel',\n",
       " 'mobile',\n",
       " 'play',\n",
       " 'official',\n",
       " 'ultimate',\n",
       " 'spiderman',\n",
       " 'game',\n",
       " '£',\n",
       " '450',\n",
       " 'ur',\n",
       " 'mobile',\n",
       " 'right',\n",
       " 'text',\n",
       " 'spider',\n",
       " '83338',\n",
       " 'game',\n",
       " 'll',\n",
       " 'send',\n",
       " 'u',\n",
       " 'free',\n",
       " '8ball',\n",
       " 'wallpaper',\n",
       " 'u',\n",
       " 'study',\n",
       " 'sch',\n",
       " 'go',\n",
       " 'home',\n",
       " 'ill',\n",
       " 'b',\n",
       " 'go',\n",
       " '2',\n",
       " 'sch',\n",
       " 'later',\n",
       " 'k',\n",
       " 'sent',\n",
       " 'oh',\n",
       " 'thank',\n",
       " 'loti',\n",
       " 'buy',\n",
       " '2',\n",
       " 'egg',\n",
       " 'k',\n",
       " 'sent',\n",
       " '2p',\n",
       " 'min',\n",
       " 'germany',\n",
       " '08448350055',\n",
       " 'bt',\n",
       " 'line',\n",
       " '2p',\n",
       " 'min',\n",
       " 'check',\n",
       " 'planettalkinstantcom',\n",
       " 'info',\n",
       " 'ts',\n",
       " 'cs',\n",
       " 'text',\n",
       " 'stop',\n",
       " 'opt',\n",
       " 'ofcourse',\n",
       " 'upload',\n",
       " 'song',\n",
       " 'fuck',\n",
       " 'family',\n",
       " 'go',\n",
       " 'rhode',\n",
       " 'island',\n",
       " 'fuck',\n",
       " 'leave',\n",
       " 'week',\n",
       " 'new',\n",
       " 'bong',\n",
       " 'gt',\n",
       " 'pick',\n",
       " 'point',\n",
       " 'go',\n",
       " '2',\n",
       " 'yeovil',\n",
       " 'motor',\n",
       " 'project',\n",
       " '4',\n",
       " '3',\n",
       " 'hour',\n",
       " 'u',\n",
       " 'home',\n",
       " '12',\n",
       " '2',\n",
       " '530',\n",
       " 'max',\n",
       " 'easy',\n",
       " 'li',\n",
       " 'hai',\n",
       " 'bore',\n",
       " 'da',\n",
       " 'lecturer',\n",
       " 'repeat',\n",
       " 'week',\n",
       " 'stuff',\n",
       " 'waste',\n",
       " 'time',\n",
       " 'urgent',\n",
       " 'try',\n",
       " 'contact',\n",
       " 'weekend',\n",
       " 'draw',\n",
       " 'show',\n",
       " 'u',\n",
       " 'win',\n",
       " '£',\n",
       " '1000',\n",
       " 'prize',\n",
       " 'guarantee',\n",
       " '09064017295',\n",
       " 'claim',\n",
       " 'code',\n",
       " 'k52',\n",
       " 'valid',\n",
       " '12hrs',\n",
       " '150p',\n",
       " 'pm',\n",
       " 'shall',\n",
       " 'dear',\n",
       " 'have',\n",
       " 'food',\n",
       " 'see',\n",
       " 's',\n",
       " 'holby',\n",
       " 'hope',\n",
       " 'work',\n",
       " 'not',\n",
       " 'stressful',\n",
       " 'gr8',\n",
       " 'day',\n",
       " 'probably',\n",
       " 'ltgt',\n",
       " 'todaysundaysunday',\n",
       " 'holidayso',\n",
       " 'work',\n",
       " 'yes',\n",
       " 'princess',\n",
       " 'want',\n",
       " 'night',\n",
       " 'wish',\n",
       " 'command',\n",
       " 'dhoni',\n",
       " 'luck',\n",
       " 'win',\n",
       " 'big',\n",
       " 'titleso',\n",
       " 'win',\n",
       " 's',\n",
       " 'mummys',\n",
       " 'boy',\n",
       " 'good',\n",
       " 'bad',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'mummy',\n",
       " 'wait',\n",
       " 'hmmmm',\n",
       " 'ok',\n",
       " 'lor',\n",
       " 'ü',\n",
       " 'reach',\n",
       " 'message',\n",
       " 'obviously',\n",
       " 'people',\n",
       " 'cool',\n",
       " 'college',\n",
       " 'life',\n",
       " 'go',\n",
       " 'home',\n",
       " 'yup',\n",
       " 'think',\n",
       " 'slide',\n",
       " 'ok',\n",
       " 'lor',\n",
       " 'urgent',\n",
       " 'weekend',\n",
       " 'draw',\n",
       " 'show',\n",
       " 'win',\n",
       " '£',\n",
       " '1000',\n",
       " 'cash',\n",
       " 'spanish',\n",
       " 'holiday',\n",
       " '09050000332',\n",
       " 'claim',\n",
       " 'tc',\n",
       " 'rstm',\n",
       " 'sw7',\n",
       " '3ss',\n",
       " '150ppm',\n",
       " 'garden',\n",
       " 'ready',\n",
       " 'summer',\n",
       " 'free',\n",
       " 'selection',\n",
       " 'summer',\n",
       " 'bulb',\n",
       " 'seed',\n",
       " 'worth',\n",
       " '£',\n",
       " '3350',\n",
       " 'scotsman',\n",
       " 'saturday',\n",
       " 'stop',\n",
       " 'go2',\n",
       " 'notxtcouk',\n",
       " 'httptms',\n",
       " 'widelivecomindex',\n",
       " 'wmlid820554ad0a1705572711firsttrue¡c',\n",
       " 'c',\n",
       " 'ringtone',\n",
       " 'shall',\n",
       " 'bring',\n",
       " 'bottle',\n",
       " 'wine',\n",
       " 'amuse',\n",
       " 'joke',\n",
       " 'i‘ll',\n",
       " 'bring',\n",
       " 'treasure',\n",
       " 'moment',\n",
       " 'spend',\n",
       " 'u',\n",
       " 'goin',\n",
       " '2nite',\n",
       " 'txt',\n",
       " '86888',\n",
       " 'claim',\n",
       " 'reward',\n",
       " '3',\n",
       " 'hour',\n",
       " 'talk',\n",
       " 'time',\n",
       " 'use',\n",
       " 'phone',\n",
       " 'subscribe6gbpmnth',\n",
       " 'inc',\n",
       " '3hrs',\n",
       " '16',\n",
       " 'stoptxtstop',\n",
       " 'wwwgambtv',\n",
       " 'ok',\n",
       " 'thk',\n",
       " 'get',\n",
       " 'u',\n",
       " 'wan',\n",
       " '2',\n",
       " 'come',\n",
       " 'wat',\n",
       " 'december',\n",
       " 'mobile',\n",
       " '11mth',\n",
       " 'entitle',\n",
       " 'update',\n",
       " 'late',\n",
       " 'colour',\n",
       " 'camera',\n",
       " 'mobile',\n",
       " 'free',\n",
       " 'mobile',\n",
       " 'update',\n",
       " 'co',\n",
       " 'free',\n",
       " '08002986906',\n",
       " 'hear',\n",
       " 'loud',\n",
       " 'scream',\n",
       " 'ltgt',\n",
       " 'minute',\n",
       " 'cause',\n",
       " 'gyno',\n",
       " 'shove',\n",
       " 'thing',\n",
       " 'not',\n",
       " 'belong',\n",
       " 'sorry',\n",
       " 'ill',\n",
       " 'later',\n",
       " 'arun',\n",
       " 'u',\n",
       " 'transfr',\n",
       " 'd',\n",
       " 'amt',\n",
       " 'sparkling',\n",
       " 'shopping',\n",
       " 'break',\n",
       " '45',\n",
       " 'person',\n",
       " '0121',\n",
       " '2025050',\n",
       " 'visit',\n",
       " 'wwwshortbreaksorguk',\n",
       " 'wish',\n",
       " 'beautiful',\n",
       " 'day',\n",
       " 'moment',\n",
       " 'reveal',\n",
       " 'thing',\n",
       " 'smile',\n",
       " 'enjoy',\n",
       " 'm',\n",
       " 'wonder',\n",
       " 'right',\n",
       " 's',\n",
       " 'chick',\n",
       " 'huge',\n",
       " 'boob',\n",
       " 'hello',\n",
       " 'wat',\n",
       " 'talk',\n",
       " 'email',\n",
       " 'address',\n",
       " 'sing',\n",
       " 'hu',\n",
       " 'think',\n",
       " 'important',\n",
       " 'find',\n",
       " 'female',\n",
       " 'know',\n",
       " 'place',\n",
       " 'preferably',\n",
       " 'citizen',\n",
       " 'smart',\n",
       " 'help',\n",
       " 'navigate',\n",
       " 'thing',\n",
       " 'like',\n",
       " 'choose',\n",
       " 'phone',\n",
       " 'plan',\n",
       " 'require',\n",
       " 'guidance',\n",
       " 'doubt',\n",
       " 'ask',\n",
       " 'especially',\n",
       " 'girl',\n",
       " 'sac',\n",
       " 'need',\n",
       " 'carry',\n",
       " 'late',\n",
       " 'news',\n",
       " 'police',\n",
       " 'station',\n",
       " 'toilet',\n",
       " 'steal',\n",
       " 'cop',\n",
       " 'aight',\n",
       " 'pick',\n",
       " 'open',\n",
       " 'tonight',\n",
       " 'take',\n",
       " 'away',\n",
       " 'money',\n",
       " 'worry',\n",
       " 'good',\n",
       " 'journey',\n",
       " 'let',\n",
       " 'know',\n",
       " 'need',\n",
       " ...]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8cccd37-3a1a-4ccd-b3f0-58097be780c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 frequent words:\n",
      "u: 193\n",
      "not: 115\n",
      "m: 101\n",
      "2: 83\n",
      "ur: 66\n",
      "s: 64\n",
      "4: 61\n",
      "£: 54\n",
      "come: 49\n",
      "free: 47\n"
     ]
    }
   ],
   "source": [
    "all_lemmas = [lemma for lemmas_list in df['lemmas'] for lemma in lemmas_list]\n",
    "freq_dist = Counter(all_lemmas)\n",
    "\n",
    "print(\"Top 10 frequent words:\")\n",
    "for word, freq in freq_dist.most_common(10):\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75c4a820-99cf-4abd-8650-0f46e882e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.19.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murduhack\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urduhack\\__init__.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconll\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoNLL\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresources\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download\n\u001b[32m      9\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mget_info\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnormalize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdownload\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCoNLL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urduhack\\pipeline\\__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# coding: utf8\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"Pipeline module\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urduhack\\pipeline\\core.py:7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mPipeline that runs tokenize\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparsers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NerParser\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparsers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NormalizeParser\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparsers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpos_tagger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PosTaggerParser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urduhack\\pipeline\\parsers\\ner.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# coding: utf8\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"Parser for performing ner detection\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murduhack\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m predict_ner\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parser\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNerParser\u001b[39;00m(Parser):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urduhack\\models\\ner\\__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# coding: utf8\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"Ner Model\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m predict_ner\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urduhack\\models\\ner\\predict.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murduhack\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NER_WEIGHTS_PATH, NER_WORD2IDX_PATH, NER_TAG2IDX_PATH\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murduhack\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mner\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _bi_lstm_crf_model\n\u001b[32m     13\u001b[39m _NER_MODEL, _WORD2IDX, _IDX2TAG = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_metadata\u001b[39m(model_path: \u001b[38;5;28mstr\u001b[39m, word2idx_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     17\u001b[39m                    tag2idx_path: \u001b[38;5;28mstr\u001b[39m, max_len: \u001b[38;5;28mint\u001b[39m = \u001b[32m55\u001b[39m) -> Tuple[tf.keras.Model, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urduhack\\models\\ner\\model.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"NER Tensorflow Model\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf2crf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CRF\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_bi_lstm_crf_model\u001b[39m(n_words: \u001b[38;5;28mint\u001b[39m, n_tags: \u001b[38;5;28mint\u001b[39m, max_len: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Ner model\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf2crf\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m0.1.30\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcrf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CRF\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf2crf\\crf.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfa\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mK\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCRF\u001b[39;00m(tf.keras.layers.Layer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\__init__.py:23\u001b[39m\n\u001b[32m     20\u001b[39m _check_tf_version()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\activations\\__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgelu\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhardshrink\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlisht\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lisht\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\activations\\gelu.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_addons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[32m     22\u001b[39m \u001b[38;5;129m@tf\u001b[39m.keras.utils.register_keras_serializable(package=\u001b[33m\"\u001b[39m\u001b[33mAddons\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> tf.Tensor:\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m \u001b[33;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\types.py:29\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Version(tf.__version__).release >= Version(\u001b[33m\"\u001b[39m\u001b[33m2.13\u001b[39m\u001b[33m\"\u001b[39m).release:\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# importing internal symbols.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m Version(tf.__version__).release >= Version(\u001b[33m\"\u001b[39m\u001b[33m2.5\u001b[39m\u001b[33m\"\u001b[39m).release:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "import urduhack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c3e8c76-be4e-438b-b4a0-15bbc89e9d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urduhack\n",
      "  Using cached urduhack-1.1.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting tf2crf (from urduhack)\n",
      "  Using cached tf2crf-0.1.33-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-datasets~=3.1 (from urduhack)\n",
      "  Using cached tensorflow_datasets-3.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting Click~=7.1 (from urduhack)\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urduhack) (2024.11.6)\n",
      "Collecting absl-py (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting attrs>=18.1.0 (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting dill (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting future (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.3.1)\n",
      "Collecting promise (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting protobuf>=3.6.1 (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.32.4)\n",
      "Requirement already satisfied: six in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.17.0)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached tensorflow_metadata-1.17.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting termcolor (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (4.67.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.17.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (2025.6.15)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting tensorflow>=2.1.0 (from tf2crf->urduhack)\n",
      "  Downloading tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorflow-addons>=0.8.2 (from tf2crf->urduhack)\n",
      "  Downloading tensorflow_addons-0.22.0-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (80.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (4.14.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy (from tensorflow-datasets~=3.1->urduhack)\n",
      "  Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading h5py-3.14.0-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.1.0->tf2crf->urduhack) (14.0.0)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow>=2.1.0->tf2crf->urduhack)\n",
      "  Downloading optree-0.16.0-cp311-cp311-win_amd64.whl.metadata (31 kB)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons>=0.8.2->tf2crf->urduhack)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.1.0->tf2crf->urduhack) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow>=2.1.0->tf2crf->urduhack) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow>=2.1.0->tf2crf->urduhack) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->tensorflow-datasets~=3.1->urduhack) (0.4.6)\n",
      "Downloading urduhack-1.1.1-py3-none-any.whl (105 kB)\n",
      "Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Using cached tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached tensorflow_metadata-1.17.1-py3-none-any.whl (31 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\n",
      "Downloading tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
      "   ---------------------------------------- 0.0/375.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/375.9 MB 6.3 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 2.6/375.9 MB 7.2 MB/s eta 0:00:52\n",
      "   ---------------------------------------- 4.5/375.9 MB 7.7 MB/s eta 0:00:49\n",
      "    --------------------------------------- 6.0/375.9 MB 7.7 MB/s eta 0:00:49\n",
      "    --------------------------------------- 7.3/375.9 MB 7.3 MB/s eta 0:00:51\n",
      "    --------------------------------------- 8.7/375.9 MB 7.1 MB/s eta 0:00:53\n",
      "   - -------------------------------------- 10.0/375.9 MB 6.9 MB/s eta 0:00:54\n",
      "   - -------------------------------------- 11.0/375.9 MB 6.7 MB/s eta 0:00:55\n",
      "   - -------------------------------------- 12.3/375.9 MB 6.7 MB/s eta 0:00:55\n",
      "   - -------------------------------------- 13.9/375.9 MB 6.7 MB/s eta 0:00:55\n",
      "   - -------------------------------------- 15.2/375.9 MB 6.6 MB/s eta 0:00:55\n",
      "   - -------------------------------------- 16.3/375.9 MB 6.6 MB/s eta 0:00:55\n",
      "   - -------------------------------------- 17.6/375.9 MB 6.4 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 18.9/375.9 MB 6.5 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 20.7/375.9 MB 6.6 MB/s eta 0:00:54\n",
      "   -- ------------------------------------- 22.3/375.9 MB 6.6 MB/s eta 0:00:54\n",
      "   -- ------------------------------------- 23.6/375.9 MB 6.7 MB/s eta 0:00:53\n",
      "   -- ------------------------------------- 25.4/375.9 MB 6.7 MB/s eta 0:00:53\n",
      "   -- ------------------------------------- 27.0/375.9 MB 6.8 MB/s eta 0:00:52\n",
      "   --- ------------------------------------ 28.6/375.9 MB 6.8 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 30.1/375.9 MB 6.9 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 31.5/375.9 MB 6.9 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 33.0/375.9 MB 6.9 MB/s eta 0:00:50\n",
      "   --- ------------------------------------ 34.6/375.9 MB 6.9 MB/s eta 0:00:50\n",
      "   --- ------------------------------------ 35.7/375.9 MB 6.8 MB/s eta 0:00:50\n",
      "   --- ------------------------------------ 37.2/375.9 MB 6.8 MB/s eta 0:00:50\n",
      "   ---- ----------------------------------- 38.8/375.9 MB 6.9 MB/s eta 0:00:50\n",
      "   ---- ----------------------------------- 40.4/375.9 MB 6.9 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 41.9/375.9 MB 6.9 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 43.3/375.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 44.6/375.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 45.9/375.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 47.2/375.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 48.8/375.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 49.8/375.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 51.1/375.9 MB 6.7 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 52.4/375.9 MB 6.8 MB/s eta 0:00:48\n",
      "   ----- ---------------------------------- 53.7/375.9 MB 6.7 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 55.1/375.9 MB 6.7 MB/s eta 0:00:48\n",
      "   ----- ---------------------------------- 56.1/375.9 MB 6.7 MB/s eta 0:00:48\n",
      "   ------ --------------------------------- 57.4/375.9 MB 6.6 MB/s eta 0:00:48\n",
      "   ------ --------------------------------- 58.5/375.9 MB 6.6 MB/s eta 0:00:48\n",
      "   ------ --------------------------------- 60.3/375.9 MB 6.7 MB/s eta 0:00:48\n",
      "   ------ --------------------------------- 61.9/375.9 MB 6.7 MB/s eta 0:00:47\n",
      "   ------ --------------------------------- 63.4/375.9 MB 6.7 MB/s eta 0:00:47\n",
      "   ------ --------------------------------- 64.7/375.9 MB 6.7 MB/s eta 0:00:47\n",
      "   ------- -------------------------------- 66.1/375.9 MB 6.7 MB/s eta 0:00:47\n",
      "   ------- -------------------------------- 67.6/375.9 MB 6.7 MB/s eta 0:00:46\n",
      "   ------- -------------------------------- 68.9/375.9 MB 6.7 MB/s eta 0:00:46\n",
      "   ------- -------------------------------- 70.5/375.9 MB 6.7 MB/s eta 0:00:46\n",
      "   ------- -------------------------------- 72.1/375.9 MB 6.7 MB/s eta 0:00:46\n",
      "   ------- -------------------------------- 73.7/375.9 MB 6.7 MB/s eta 0:00:45\n",
      "   -------- ------------------------------- 75.5/375.9 MB 6.8 MB/s eta 0:00:45\n",
      "   -------- ------------------------------- 76.8/375.9 MB 6.8 MB/s eta 0:00:45\n",
      "   -------- ------------------------------- 78.1/375.9 MB 6.8 MB/s eta 0:00:44\n",
      "   -------- ------------------------------- 79.4/375.9 MB 6.8 MB/s eta 0:00:44\n",
      "   -------- ------------------------------- 80.7/375.9 MB 6.8 MB/s eta 0:00:44\n",
      "   -------- ------------------------------- 82.1/375.9 MB 6.7 MB/s eta 0:00:44\n",
      "   -------- ------------------------------- 83.4/375.9 MB 6.7 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 84.7/375.9 MB 6.7 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 86.0/375.9 MB 6.7 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 87.6/375.9 MB 6.7 MB/s eta 0:00:43\n",
      "   --------- ------------------------------ 89.1/375.9 MB 6.7 MB/s eta 0:00:43\n",
      "   --------- ------------------------------ 90.7/375.9 MB 6.7 MB/s eta 0:00:43\n",
      "   --------- ------------------------------ 92.5/375.9 MB 6.8 MB/s eta 0:00:42\n",
      "   ---------- ----------------------------- 94.4/375.9 MB 6.8 MB/s eta 0:00:42\n",
      "   ---------- ----------------------------- 95.9/375.9 MB 6.8 MB/s eta 0:00:42\n",
      "   ---------- ----------------------------- 97.3/375.9 MB 6.8 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 98.6/375.9 MB 6.8 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 100.1/375.9 MB 6.8 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 101.7/375.9 MB 6.8 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 103.0/375.9 MB 6.8 MB/s eta 0:00:41\n",
      "   ----------- ---------------------------- 104.3/375.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 105.9/375.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 107.2/375.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 108.8/375.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 110.4/375.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ----------- ---------------------------- 111.4/375.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ------------ --------------------------- 113.2/375.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ------------ --------------------------- 114.6/375.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ------------ --------------------------- 116.1/375.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ------------ --------------------------- 117.7/375.9 MB 6.8 MB/s eta 0:00:38\n",
      "   ------------ --------------------------- 119.3/375.9 MB 6.8 MB/s eta 0:00:38\n",
      "   ------------ --------------------------- 121.1/375.9 MB 6.9 MB/s eta 0:00:38\n",
      "   ------------- -------------------------- 122.7/375.9 MB 6.9 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 124.3/375.9 MB 6.9 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 125.8/375.9 MB 6.9 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 126.9/375.9 MB 6.8 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 127.4/375.9 MB 6.8 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 128.2/375.9 MB 6.8 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 128.7/375.9 MB 6.7 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 129.8/375.9 MB 6.7 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 130.5/375.9 MB 6.7 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 131.1/375.9 MB 6.6 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 131.6/375.9 MB 6.6 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 132.6/375.9 MB 6.6 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 133.4/375.9 MB 6.5 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 134.2/375.9 MB 6.5 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 135.0/375.9 MB 6.5 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 135.5/375.9 MB 6.5 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 136.8/375.9 MB 6.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 137.9/375.9 MB 6.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 138.4/375.9 MB 6.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 138.7/375.9 MB 6.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 139.2/375.9 MB 6.3 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 139.5/375.9 MB 6.3 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 140.0/375.9 MB 6.2 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 140.2/375.9 MB 6.2 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 140.8/375.9 MB 6.1 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 141.6/375.9 MB 6.1 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 141.8/375.9 MB 6.1 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 142.6/375.9 MB 6.0 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 143.4/375.9 MB 6.0 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 143.9/375.9 MB 6.0 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 144.4/375.9 MB 6.0 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 145.0/375.9 MB 5.9 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 145.8/375.9 MB 5.9 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 146.5/375.9 MB 5.9 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 147.1/375.9 MB 5.9 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 147.3/375.9 MB 5.9 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 147.3/375.9 MB 5.9 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 147.3/375.9 MB 5.9 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 148.4/375.9 MB 5.7 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 148.6/375.9 MB 5.7 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 149.2/375.9 MB 5.7 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 150.2/375.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 151.0/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 151.8/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 152.8/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 154.1/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 155.2/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 156.2/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 157.0/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 157.8/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 158.6/375.9 MB 5.6 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 159.9/375.9 MB 5.6 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 161.5/375.9 MB 5.6 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 162.5/375.9 MB 5.6 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 163.6/375.9 MB 5.6 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 164.4/375.9 MB 5.6 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 165.2/375.9 MB 5.5 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 165.9/375.9 MB 5.5 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 166.7/375.9 MB 5.5 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 167.5/375.9 MB 5.5 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 168.3/375.9 MB 5.5 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 168.6/375.9 MB 5.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 169.3/375.9 MB 5.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 170.1/375.9 MB 5.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 170.9/375.9 MB 5.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 171.4/375.9 MB 5.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 172.2/375.9 MB 5.3 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 173.0/375.9 MB 5.3 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 173.8/375.9 MB 5.3 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 174.9/375.9 MB 5.3 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 175.6/375.9 MB 5.3 MB/s eta 0:00:38\n",
      "   ------------------ --------------------- 176.4/375.9 MB 5.2 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 177.2/375.9 MB 5.2 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 178.0/375.9 MB 5.2 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 178.5/375.9 MB 5.2 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 179.6/375.9 MB 5.2 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 180.6/375.9 MB 5.1 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 181.4/375.9 MB 5.1 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 182.5/375.9 MB 5.1 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 183.2/375.9 MB 5.1 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 184.0/375.9 MB 5.0 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 184.8/375.9 MB 5.0 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 185.3/375.9 MB 5.0 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 186.4/375.9 MB 5.0 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 187.2/375.9 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 188.0/375.9 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 188.7/375.9 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 189.5/375.9 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 190.6/375.9 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 191.1/375.9 MB 4.8 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 191.4/375.9 MB 4.8 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 191.9/375.9 MB 4.8 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 192.4/375.9 MB 4.7 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 192.7/375.9 MB 4.7 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 193.5/375.9 MB 4.7 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 194.0/375.9 MB 4.7 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 195.0/375.9 MB 4.7 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 195.3/375.9 MB 4.7 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 196.1/375.9 MB 4.6 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 196.9/375.9 MB 4.6 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 197.9/375.9 MB 4.6 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 199.2/375.9 MB 4.6 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 200.8/375.9 MB 4.6 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 201.3/375.9 MB 4.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 201.6/375.9 MB 4.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 202.1/375.9 MB 4.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 202.1/375.9 MB 4.5 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 202.6/375.9 MB 4.4 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 202.6/375.9 MB 4.4 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 202.6/375.9 MB 4.4 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 203.7/375.9 MB 4.3 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 204.7/375.9 MB 4.2 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 205.5/375.9 MB 4.2 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 206.3/375.9 MB 4.2 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 207.1/375.9 MB 4.2 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 208.4/375.9 MB 4.2 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 209.5/375.9 MB 4.2 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 211.8/375.9 MB 4.2 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 213.9/375.9 MB 4.2 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 215.5/375.9 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 217.1/375.9 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 218.6/375.9 MB 4.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 220.5/375.9 MB 4.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 222.6/375.9 MB 4.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 224.4/375.9 MB 4.3 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 225.4/375.9 MB 4.2 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 226.5/375.9 MB 4.2 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 228.3/375.9 MB 4.2 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 230.4/375.9 MB 4.3 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 232.5/375.9 MB 4.3 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 234.6/375.9 MB 4.3 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 236.5/375.9 MB 4.3 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 238.8/375.9 MB 4.4 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 241.2/375.9 MB 4.4 MB/s eta 0:00:31\n",
      "   ------------------------- -------------- 243.3/375.9 MB 4.4 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 245.1/375.9 MB 4.4 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 247.2/375.9 MB 4.4 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 249.0/375.9 MB 4.5 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 251.1/375.9 MB 4.5 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 253.0/375.9 MB 4.5 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 255.3/375.9 MB 4.5 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 257.2/375.9 MB 4.5 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 259.0/375.9 MB 4.5 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 260.8/375.9 MB 4.5 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 262.7/375.9 MB 4.6 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 264.8/375.9 MB 4.6 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 266.6/375.9 MB 4.6 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 268.7/375.9 MB 4.7 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 271.1/375.9 MB 4.7 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 273.2/375.9 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 275.0/375.9 MB 4.8 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 276.8/375.9 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 278.7/375.9 MB 4.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 280.0/375.9 MB 4.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 281.8/375.9 MB 4.9 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 283.6/375.9 MB 5.0 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 285.7/375.9 MB 5.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 287.3/375.9 MB 5.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 288.9/375.9 MB 5.0 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 290.7/375.9 MB 5.1 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 292.6/375.9 MB 5.1 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 293.9/375.9 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 295.7/375.9 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 297.5/375.9 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 299.1/375.9 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 300.7/375.9 MB 5.3 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 302.3/375.9 MB 5.4 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 303.6/375.9 MB 5.4 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 304.9/375.9 MB 5.4 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 305.9/375.9 MB 5.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 307.2/375.9 MB 5.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 308.3/375.9 MB 5.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 309.6/375.9 MB 5.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 311.2/375.9 MB 5.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 312.5/375.9 MB 5.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 314.0/375.9 MB 5.6 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 315.9/375.9 MB 5.7 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 318.0/375.9 MB 5.7 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 319.6/375.9 MB 5.8 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 321.1/375.9 MB 5.8 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 323.0/375.9 MB 5.8 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 324.8/375.9 MB 5.9 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 326.4/375.9 MB 5.9 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 327.9/375.9 MB 5.9 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 329.3/375.9 MB 5.9 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 330.6/375.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 332.7/375.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 334.2/375.9 MB 6.0 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 335.8/375.9 MB 6.0 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 338.2/375.9 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 340.3/375.9 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 341.8/375.9 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 343.4/375.9 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 345.2/375.9 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 346.8/375.9 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 348.4/375.9 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 350.2/375.9 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 351.8/375.9 MB 6.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 353.4/375.9 MB 6.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 355.5/375.9 MB 6.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 357.3/375.9 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 358.9/375.9 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 361.0/375.9 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 363.1/375.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 364.9/375.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  366.7/375.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.3/375.9 MB 6.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  370.7/375.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.6/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 375.9/375.9 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.3/4.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl (209 kB)\n",
      "Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.9 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.5/12.9 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.6/12.9 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.7/12.9 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.9 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.8/2.9 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.1/26.4 MB 10.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.9/26.4 MB 9.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.8/26.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.1/26.4 MB 9.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.2/26.4 MB 10.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 10.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.6/26.4 MB 9.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.2/26.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.8/26.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.6/26.4 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.4 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_addons-0.22.0-cp311-cp311-win_amd64.whl (719 kB)\n",
      "   ---------------------------------------- 0.0/719.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 719.8/719.8 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp311-cp311-win_amd64.whl (314 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21644 sha256=7addc0015cfe3d0ff4c9726888419b00c7f3f2a436df50ee84c4a516b36ec741\n",
      "  Stored in directory: c:\\users\\nooru\\appdata\\local\\pip\\cache\\wheels\\90\\74\\b1\\9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, typeguard, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, promise, optree, opt-einsum, numpy, markdown, grpcio, google-pasta, gast, future, dill, Click, attrs, astunparse, absl-py, tensorflow-addons, tensorboard, ml-dtypes, h5py, googleapis-common-protos, tensorflow-metadata, keras, tensorflow-datasets, tensorflow, tf2crf, urduhack\n",
      "\n",
      "   - --------------------------------------  1/34 [libclang]\n",
      "   - --------------------------------------  1/34 [libclang]\n",
      "   - --------------------------------------  1/34 [libclang]\n",
      "   - --------------------------------------  1/34 [libclang]\n",
      "   --- ------------------------------------  3/34 [werkzeug]\n",
      "   --- ------------------------------------  3/34 [werkzeug]\n",
      "   --- ------------------------------------  3/34 [werkzeug]\n",
      "   --- ------------------------------------  3/34 [werkzeug]\n",
      "   --- ------------------------------------  3/34 [werkzeug]\n",
      "   --- ------------------------------------  3/34 [werkzeug]\n",
      "   ------ --------------------------------  6/34 [tensorflow-io-gcs-filesystem]\n",
      "   --------- ------------------------------  8/34 [protobuf]\n",
      "   --------- ------------------------------  8/34 [protobuf]\n",
      "   --------- ------------------------------  8/34 [protobuf]\n",
      "   ---------- -----------------------------  9/34 [promise]\n",
      "   ----------- ---------------------------- 10/34 [optree]\n",
      "   ----------- ---------------------------- 10/34 [optree]\n",
      "   ------------ --------------------------- 11/34 [opt-einsum]\n",
      "   ------------ --------------------------- 11/34 [opt-einsum]\n",
      "  Attempting uninstall: numpy\n",
      "   ------------ --------------------------- 11/34 [opt-einsum]\n",
      "    Found existing installation: numpy 2.3.1\n",
      "   ------------ --------------------------- 11/34 [opt-einsum]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "    Uninstalling numpy-2.3.1:\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   -------------- ------------------------- 12/34 [numpy]\n",
      "   --------------- ------------------------ 13/34 [markdown]\n",
      "   --------------- ------------------------ 13/34 [markdown]\n",
      "   --------------- ------------------------ 13/34 [markdown]\n",
      "   ---------------- ----------------------- 14/34 [grpcio]\n",
      "   ---------------- ----------------------- 14/34 [grpcio]\n",
      "   ---------------- ----------------------- 14/34 [grpcio]\n",
      "   ---------------- ----------------------- 14/34 [grpcio]\n",
      "   ---------------- ----------------------- 14/34 [grpcio]\n",
      "   ----------------- ---------------------- 15/34 [google-pasta]\n",
      "   ----------------- ---------------------- 15/34 [google-pasta]\n",
      "   ------------------ --------------------- 16/34 [gast]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   -------------------- ------------------- 17/34 [future]\n",
      "   --------------------- ------------------ 18/34 [dill]\n",
      "   --------------------- ------------------ 18/34 [dill]\n",
      "   --------------------- ------------------ 18/34 [dill]\n",
      "  Attempting uninstall: Click\n",
      "   --------------------- ------------------ 18/34 [dill]\n",
      "    Found existing installation: click 8.2.1\n",
      "   --------------------- ------------------ 18/34 [dill]\n",
      "    Uninstalling click-8.2.1:\n",
      "   --------------------- ------------------ 18/34 [dill]\n",
      "      Successfully uninstalled click-8.2.1\n",
      "   --------------------- ------------------ 18/34 [dill]\n",
      "   ---------------------- ----------------- 19/34 [Click]\n",
      "   ---------------------- ----------------- 19/34 [Click]\n",
      "   ----------------------- ---------------- 20/34 [attrs]\n",
      "   ------------------------ --------------- 21/34 [astunparse]\n",
      "   ------------------------- -------------- 22/34 [absl-py]\n",
      "   ------------------------- -------------- 22/34 [absl-py]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   --------------------------- ------------ 23/34 [tensorflow-addons]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ---------------------------- ----------- 24/34 [tensorboard]\n",
      "   ----------------------------- ---------- 25/34 [ml-dtypes]\n",
      "   ------------------------------ --------- 26/34 [h5py]\n",
      "   ------------------------------ --------- 26/34 [h5py]\n",
      "   ------------------------------ --------- 26/34 [h5py]\n",
      "   ------------------------------ --------- 26/34 [h5py]\n",
      "   ------------------------------ --------- 26/34 [h5py]\n",
      "   ------------------------------ --------- 26/34 [h5py]\n",
      "   ------------------------------- -------- 27/34 [googleapis-common-protos]\n",
      "   ------------------------------- -------- 27/34 [googleapis-common-protos]\n",
      "   ------------------------------- -------- 27/34 [googleapis-common-protos]\n",
      "   ------------------------------- -------- 27/34 [googleapis-common-protos]\n",
      "   ------------------------------- -------- 27/34 [googleapis-common-protos]\n",
      "   -------------------------------- ------- 28/34 [tensorflow-metadata]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ---------------------------------- ----- 29/34 [keras]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ----------------------------------- ---- 30/34 [tensorflow-datasets]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------ --- 31/34 [tensorflow]\n",
      "   ------------------------------------- -- 32/34 [tf2crf]\n",
      "   -------------------------------------- - 33/34 [urduhack]\n",
      "   -------------------------------------- - 33/34 [urduhack]\n",
      "   -------------------------------------- - 33/34 [urduhack]\n",
      "   -------------------------------------- - 33/34 [urduhack]\n",
      "   -------------------------------------- - 33/34 [urduhack]\n",
      "   ---------------------------------------- 34/34 [urduhack]\n",
      "\n",
      "Successfully installed Click-7.1.2 absl-py-2.3.0 astunparse-1.6.3 attrs-25.3.0 dill-0.4.0 flatbuffers-25.2.10 future-1.0.0 gast-0.6.0 google-pasta-0.2.0 googleapis-common-protos-1.70.0 grpcio-1.73.0 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 markdown-3.8.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 promise-2.3 protobuf-5.29.5 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-addons-0.22.0 tensorflow-datasets-3.2.1 tensorflow-io-gcs-filesystem-0.31.0 tensorflow-metadata-1.17.1 termcolor-3.1.0 tf2crf-0.1.33 typeguard-2.13.3 urduhack-1.1.1 werkzeug-3.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'promise' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'promise'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts futurize.exe and pasteurize.exe are installed in 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe and toco.exe are installed in 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script urduhack.exe is installed in 'C:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "typer 0.16.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install urduhack\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
