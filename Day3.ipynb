{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52116515-62f6-4732-9092-4fddc93397c8",
   "metadata": {},
   "source": [
    "Dataset Used:\n",
    "\n",
    "https://www.kaggle.com/datasets/etaifour/trump-speeches-audio-and-word-transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe413ef",
   "metadata": {},
   "source": [
    "Load actual Text data for transcription accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344875d-1efe-4f5c-8c98-fb74c8736c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual transcript of the speech: \n",
      "Yesterday I gave out one hundred and fifteen miles worth of wall 115 miles in Texas and it's going to be built hopefully rapidly . I'm going there at the end of January . For the start of construction that's a big stretch because we're talking about 500 to 550 miles so it's a 2000 mile border . Much of it has mountains and region where you can't get across . So we're looking at between 500 and 550 so we gave out a hundred and fifteen yesterday and we gave it out at a great price . So we have a great wall there and we have other sections to give out . One other thing people don't understand or know or whatever but they might as well as is not really tall . We've renovated massive amounts of very good wall . Wall that was good but was in bad shape and so do you don't have to replace it . But you have to renovate it and we've renovated  massive amount of wall . And in addition to that and I think very very importantly we built a lot of new wall . So it's all being built to the new piece . The new section is very very exciting . What's going on there and you'll see it . Because in January I'm going there we're almost having a groundbreaking it's such a big section . It's probably the biggest sec biggest section will get out . So while we're fighting over funding we're also building and it is my hope to have this done completed all five hundred to five hundred and fifty miles to have it either renovated or brand new by Election Day Hey NBC News viewers thanks for checking out our YouTube channel . Subscribe by clicking on that button down here and click on any of the videos over here to watch the latest interviews show highlights and digital exclusives . Thanks for watching .\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('small.json', encoding = 'utf-8-sig') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "speech_words = [entry['value'].strip() for entry in data['words']] #remive leading and trailing whitespaces then assign to entry variable\n",
    "actual_transcript = ' '.join(speech_words)\n",
    "print(\"Actual transcript of the speech: \")\n",
    "print(actual_transcript)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07445f2e",
   "metadata": {},
   "source": [
    "Whisper \n",
    "- Automatic speech recognition (ASR) system\n",
    "- model that can transcribe audio to written text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec9d6c90-3156-4a22-adb9-cca65ff09e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper\n",
      "  Using cached whisper-1.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\nooru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from whisper) (1.17.0)\n",
      "Building wheels for collected packages: whisper\n",
      "  Building wheel for whisper (setup.py): started\n",
      "  Building wheel for whisper (setup.py): finished with status 'done'\n",
      "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41476 sha256=7da4c068104d16f1977d214a9b3a1b66f322b12145d32f502b75d3a5a5645d5b\n",
      "  Stored in directory: c:\\users\\nooru\\appdata\\local\\pip\\cache\\wheels\\21\\65\\ee\\4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
      "Successfully built whisper\n",
      "Installing collected packages: whisper\n",
      "Successfully installed whisper-1.1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'whisper' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'whisper'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a92f46-605c-453e-a6a2-19781ac03f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804fa7f0",
   "metadata": {},
   "source": [
    "Base model\n",
    "- good accuracy and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d385309f",
   "metadata": {},
   "source": [
    ".transcribe\n",
    "- prepocess audio by splitting into chunks, convert into spectogram (visual representation of sound), pass the spectogram to whisper inorder to predict text \n",
    "- convert predicted tokens to text by joining all tokens \n",
    "\n",
    "result\n",
    "- disctionary returned by .transcribe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45597bb2-2c25-406a-a69f-2e62e22dad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nooru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Transcript:\n",
      "  Yesterday gave out 115 miles worth of wall, 115 miles in Texas. And it's going to be built, hopefully rapidly. I'm going there at the end of January for the start of construction. That's a big stretch. Because we're talking about 500 to 550 miles total. It's a 2,000 mile border, but much of it has mountains and region where you can't get across. So we're looking at between 500 and 550. So we gave out 115 yesterday. And we gave it out at a great price. So we're going to have a great wall there, and we have other sections to give out. One other thing, people don't understand or know or whatever, but they might as well as they're not really tall. We've renovated massive amounts of very good wall. Wall that was good, but was in bad shape. And so you don't have to replace it, but you have to renovate it. And we've renovated a massive amount of wall. And in addition to that, and I think very, very importantly, we built a lot of new wall. So it's all being built. The new piece, the new section is very, very exciting what's going on there. And you'll see it. Because in January, I'm going there. We're almost having a ground break, and it's such a big section. It's probably the biggest section we'll get out. So while we're finding overfunding, we're also building. And it's my hope to have this done completed, all 500 to 550 miles, to have it either renovated or brand new by election time.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"/Users/nooru/Documents/Internship_starter_week/small.mp3\") \n",
    "predicted_transcript = result['text']\n",
    "print(\"Predicted Transcript:\\n\", predicted_transcript)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b755ee",
   "metadata": {},
   "source": [
    "Text Prepocessing using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c35197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28253186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower() #to lower \n",
    "    tokens = word_tokenize(text) #split into words\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    tokens = [t for t in tokens if t not in stop_words and t not in string.punctuation] #remove stop words and punctuation\n",
    "    return tokens \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1bdf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'gave', 'one', 'hundred', 'fifteen', 'miles', 'worth', 'wall', '115', 'miles', 'texas', \"'s\", 'going', 'built', 'hopefully', 'rapidly', \"'m\", 'going', 'end', 'january', 'start', 'construction', \"'s\", 'big', 'stretch', \"'re\", 'talking', '500', '550', 'miles', \"'s\", '2000', 'mile', 'border', 'much', 'mountains', 'region', 'ca', \"n't\", 'get', 'across', \"'re\", 'looking', '500', '550', 'gave', 'hundred', 'fifteen', 'yesterday', 'gave', 'great', 'price', 'great', 'wall', 'sections', 'give', 'one', 'thing', 'people', \"n't\", 'understand', 'know', 'whatever', 'might', 'well', 'really', 'tall', \"'ve\", 'renovated', 'massive', 'amounts', 'good', 'wall', 'wall', 'good', 'bad', 'shape', \"n't\", 'replace', 'renovate', \"'ve\", 'renovated', 'massive', 'amount', 'wall', 'addition', 'think', 'importantly', 'built', 'lot', 'new', 'wall', \"'s\", 'built', 'new', 'piece', 'new', 'section', 'exciting', \"'s\", 'going', \"'ll\", 'see', 'january', \"'m\", 'going', \"'re\", 'almost', 'groundbreaking', \"'s\", 'big', 'section', \"'s\", 'probably', 'biggest', 'sec', 'biggest', 'section', 'get', \"'re\", 'fighting', 'funding', \"'re\", 'also', 'building', 'hope', 'done', 'completed', 'five', 'hundred', 'five', 'hundred', 'fifty', 'miles', 'either', 'renovated', 'brand', 'new', 'election', 'day', 'hey', 'nbc', 'news', 'viewers', 'thanks', 'checking', 'youtube', 'channel', 'subscribe', 'clicking', 'button', 'click', 'videos', 'watch', 'latest', 'interviews', 'show', 'highlights', 'digital', 'exclusives', 'thanks', 'watching']\n"
     ]
    }
   ],
   "source": [
    "actual_tokens = preprocess(actual_transcript)\n",
    "print(actual_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926275b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'gave', '115', 'miles', 'worth', 'wall', '115', 'miles', 'texas', \"'s\", 'going', 'built', 'hopefully', 'rapidly', \"'m\", 'going', 'end', 'january', 'start', 'construction', \"'s\", 'big', 'stretch', \"'re\", 'talking', '500', '550', 'miles', 'total', \"'s\", '2,000', 'mile', 'border', 'much', 'mountains', 'region', 'ca', \"n't\", 'get', 'across', \"'re\", 'looking', '500', '550.', 'gave', '115', 'yesterday', 'gave', 'great', 'price', \"'re\", 'going', 'great', 'wall', 'sections', 'give', 'one', 'thing', 'people', \"n't\", 'understand', 'know', 'whatever', 'might', 'well', \"'re\", 'really', 'tall', \"'ve\", 'renovated', 'massive', 'amounts', 'good', 'wall', 'wall', 'good', 'bad', 'shape', \"n't\", 'replace', 'renovate', \"'ve\", 'renovated', 'massive', 'amount', 'wall', 'addition', 'think', 'importantly', 'built', 'lot', 'new', 'wall', \"'s\", 'built', 'new', 'piece', 'new', 'section', 'exciting', \"'s\", 'going', \"'ll\", 'see', 'january', \"'m\", 'going', \"'re\", 'almost', 'ground', 'break', \"'s\", 'big', 'section', \"'s\", 'probably', 'biggest', 'section', \"'ll\", 'get', \"'re\", 'finding', 'overfunding', \"'re\", 'also', 'building', \"'s\", 'hope', 'done', 'completed', '500', '550', 'miles', 'either', 'renovated', 'brand', 'new', 'election', 'time']\n"
     ]
    }
   ],
   "source": [
    "pred_tokens = preprocess(predicted_transcript)\n",
    "print(pred_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90106840",
   "metadata": {},
   "source": [
    "SequenceMatcher \n",
    "- used to compare pairs of sequences such as string/list\n",
    "\n",
    ".ratio\n",
    "- calculates a similarity score b/w two sequences \n",
    "- 1 means identical, 0 means completely different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe49ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription accuracy:\n",
      "0.6612729234088457\n",
      "Transcription accuracy in percentage:\n",
      "66.127 %\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "ratio = SequenceMatcher(None, ' '.join(pred_tokens), ' '.join(actual_tokens)).ratio() #convert tokens back to strings then compare\n",
    "print(\"Transcription accuracy:\")\n",
    "print(ratio)\n",
    "print(\"Transcription accuracy in percentage:\")\n",
    "print(round(ratio * 100, 3), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4b0d6",
   "metadata": {},
   "source": [
    "moderate transcription accuracy of 66 perecnt by using base model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
